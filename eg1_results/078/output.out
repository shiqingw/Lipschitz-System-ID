==> torch device:  cuda:3
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.25
==> Further split seed:  None
==> Lipschitz constant: 4.00
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[0.5090095 0.5090095]
==> Ouput transform to be applied to the neural network:
[3.9366 3.9363]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─SandwichFc: 2-1                   [1, 64]                   4,353
│    └─SandwichFc: 2-2                   [1, 64]                   8,321
│    └─SandwichFc: 2-3                   [1, 64]                   8,321
│    └─SandwichFc: 2-4                   [1, 64]                   8,321
│    └─SandwichFc: 2-5                   [1, 64]                   8,321
│    └─SandwichFc: 2-6                   [1, 64]                   8,321
│    └─SandwichFc: 2-7                   [1, 64]                   8,321
│    └─SandwichLin: 2-8                  [1, 2]                    135
├─Sequential: 1-2                        [1, 2]                    (recursive)
│    └─SandwichFc: 2-9                   [1, 64]                   (recursive)
│    └─SandwichFc: 2-10                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-11                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-12                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-13                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-14                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-15                  [1, 64]                   (recursive)
│    └─SandwichLin: 2-16                 [1, 2]                    (recursive)
==========================================================================================
Total params: 54,420
Trainable params: 54,414
Non-trainable params: 6
Total mult-adds (M): 0.11
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.22
Estimated Total Size (MB): 0.22
==========================================================================================
==> Saving initial model weights...
==> Start training...
==> Number of param_groups in optimizer: 1
Epoch: 001 | Train Loss: 31.0965499 | Grad norm: 24.249154 | Time: 5s464ms
Epoch: 001 | Test Loss: 30.6222732 | Time: 910ms
==> Save the model at epoch 001 with test loss 30.6222732
Epoch: 002 | Train Loss: 8.1028083 | Grad norm: 22.194881 | Time: 4s124ms
Epoch: 002 | Test Loss: 0.0137636 | Time: 791ms
==> Save the model at epoch 002 with test loss 0.0137636
Epoch: 003 | Train Loss: 0.0215070 | Grad norm: 7.323471 | Time: 4s86ms
Epoch: 003 | Test Loss: 0.0172671 | Time: 790ms
Epoch: 004 | Train Loss: 0.0380086 | Grad norm: 10.155368 | Time: 4s195ms
Epoch: 004 | Test Loss: 0.0146056 | Time: 791ms
Epoch: 005 | Train Loss: 0.0408589 | Grad norm: 11.063013 | Time: 4s129ms
Epoch: 005 | Test Loss: 0.0423914 | Time: 805ms
Epoch: 006 | Train Loss: 0.0518946 | Grad norm: 12.417473 | Time: 4s102ms
Epoch: 006 | Test Loss: 0.0486056 | Time: 807ms
Epoch: 007 | Train Loss: 0.0640905 | Grad norm: 14.562921 | Time: 4s114ms
Epoch: 007 | Test Loss: 0.0369974 | Time: 854ms
Epoch: 008 | Train Loss: 0.1122872 | Grad norm: 15.918424 | Time: 4s187ms
Epoch: 008 | Test Loss: 0.0875572 | Time: 799ms
Epoch: 009 | Train Loss: 0.0879206 | Grad norm: 16.759408 | Time: 4s187ms
Epoch: 009 | Test Loss: 0.0826374 | Time: 824ms
Epoch: 010 | Train Loss: 0.0685756 | Grad norm: 14.981177 | Time: 4s73ms
Epoch: 010 | Test Loss: 0.0748053 | Time: 866ms
Epoch: 011 | Train Loss: 0.0624938 | Grad norm: 13.597019 | Time: 4s103ms
Epoch: 011 | Test Loss: 0.0489014 | Time: 850ms
Epoch: 012 | Train Loss: 0.0571940 | Grad norm: 12.557185 | Time: 4s150ms
Epoch: 012 | Test Loss: 0.0473099 | Time: 791ms
Epoch: 013 | Train Loss: 0.0526373 | Grad norm: 11.602084 | Time: 4s175ms
Epoch: 013 | Test Loss: 0.0501533 | Time: 801ms
Epoch: 014 | Train Loss: 0.0475075 | Grad norm: 10.752811 | Time: 4s176ms
Epoch: 014 | Test Loss: 0.0521712 | Time: 822ms
Epoch: 015 | Train Loss: 0.0443182 | Grad norm: 10.047440 | Time: 4s197ms
Epoch: 015 | Test Loss: 0.0444686 | Time: 831ms
Epoch: 016 | Train Loss: 0.0448420 | Grad norm: 8.977379 | Time: 4s157ms
Epoch: 016 | Test Loss: 0.0353310 | Time: 828ms
Epoch: 017 | Train Loss: 0.0388682 | Grad norm: 9.159351 | Time: 4s85ms
Epoch: 017 | Test Loss: 0.0289016 | Time: 789ms
Epoch: 018 | Train Loss: 0.0335514 | Grad norm: 8.378806 | Time: 4s196ms
Epoch: 018 | Test Loss: 0.0191120 | Time: 788ms
Epoch: 019 | Train Loss: 0.0293946 | Grad norm: 7.662380 | Time: 4s229ms
Epoch: 019 | Test Loss: 0.0279452 | Time: 790ms
Epoch: 020 | Train Loss: 0.0255830 | Grad norm: 7.043031 | Time: 4s128ms
Epoch: 020 | Test Loss: 0.0239363 | Time: 805ms
Epoch: 021 | Train Loss: 0.0255601 | Grad norm: 6.480970 | Time: 4s78ms
Epoch: 021 | Test Loss: 0.0195997 | Time: 809ms
Epoch: 022 | Train Loss: 0.0225785 | Grad norm: 5.995669 | Time: 4s63ms
Epoch: 022 | Test Loss: 0.0137092 | Time: 864ms
==> Save the model at epoch 022 with test loss 0.0137092
Epoch: 023 | Train Loss: 0.0214051 | Grad norm: 5.457358 | Time: 4s67ms
Epoch: 023 | Test Loss: 0.0185469 | Time: 792ms
Epoch: 024 | Train Loss: 0.0187333 | Grad norm: 5.131224 | Time: 4s61ms
Epoch: 024 | Test Loss: 0.0258132 | Time: 794ms
Epoch: 025 | Train Loss: 0.0178347 | Grad norm: 4.119602 | Time: 4s139ms
Epoch: 025 | Test Loss: 0.0150780 | Time: 789ms
Epoch: 026 | Train Loss: 0.0150116 | Grad norm: 4.046504 | Time: 4s208ms
Epoch: 026 | Test Loss: 0.0123578 | Time: 792ms
==> Save the model at epoch 026 with test loss 0.0123578
Epoch: 027 | Train Loss: 0.0130125 | Grad norm: 3.703781 | Time: 4s142ms
Epoch: 027 | Test Loss: 0.0136270 | Time: 809ms
Epoch: 028 | Train Loss: 0.0119199 | Grad norm: 3.214647 | Time: 4s140ms
Epoch: 028 | Test Loss: 0.0125959 | Time: 786ms
Epoch: 029 | Train Loss: 0.0113772 | Grad norm: 2.595308 | Time: 4s143ms
Epoch: 029 | Test Loss: 0.0093731 | Time: 797ms
==> Save the model at epoch 029 with test loss 0.0093731
Epoch: 030 | Train Loss: 0.0108941 | Grad norm: 2.226653 | Time: 4s207ms
Epoch: 030 | Test Loss: 0.0110131 | Time: 789ms
Epoch: 031 | Train Loss: 0.0094963 | Grad norm: 1.882228 | Time: 4s135ms
Epoch: 031 | Test Loss: 0.0080752 | Time: 792ms
==> Save the model at epoch 031 with test loss 0.0080752
Epoch: 032 | Train Loss: 0.0107647 | Grad norm: 2.391794 | Time: 4s141ms
Epoch: 032 | Test Loss: 0.0114829 | Time: 792ms
Epoch: 033 | Train Loss: 0.0088194 | Grad norm: 1.510554 | Time: 4s149ms
Epoch: 033 | Test Loss: 0.0079331 | Time: 854ms
==> Save the model at epoch 033 with test loss 0.0079331
Epoch: 034 | Train Loss: 0.0080080 | Grad norm: 1.061330 | Time: 4s71ms
Epoch: 034 | Test Loss: 0.0077023 | Time: 787ms
==> Save the model at epoch 034 with test loss 0.0077023
Epoch: 035 | Train Loss: 0.0076538 | Grad norm: 0.844798 | Time: 4s76ms
Epoch: 035 | Test Loss: 0.0074831 | Time: 787ms
==> Save the model at epoch 035 with test loss 0.0074831
Epoch: 036 | Train Loss: 0.0073951 | Grad norm: 0.733999 | Time: 4s86ms
Epoch: 036 | Test Loss: 0.0072716 | Time: 790ms
==> Save the model at epoch 036 with test loss 0.0072716
Epoch: 037 | Train Loss: 0.0072468 | Grad norm: 0.609990 | Time: 4s160ms
Epoch: 037 | Test Loss: 0.0075067 | Time: 848ms
Epoch: 038 | Train Loss: 0.0071699 | Grad norm: 0.614827 | Time: 4s819ms
Epoch: 038 | Test Loss: 0.0072756 | Time: 792ms
Epoch: 039 | Train Loss: 0.0070540 | Grad norm: 0.460347 | Time: 5s903ms
Epoch: 039 | Test Loss: 0.0071377 | Time: 791ms
==> Save the model at epoch 039 with test loss 0.0071377
Epoch: 040 | Train Loss: 0.0069832 | Grad norm: 0.425865 | Time: 5s169ms
Epoch: 040 | Test Loss: 0.0070811 | Time: 853ms
==> Save the model at epoch 040 with test loss 0.0070811
Total time: 3m22s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[0.5090095 0.5090095]
==> Output transform to be applied to the neural network (trained):
[3.9366 3.9363]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Process finished.
