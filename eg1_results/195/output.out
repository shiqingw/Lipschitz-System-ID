==> torch device:  cuda:2
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.25
==> Further split seed:  None
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[1. 1.]
==> Ouput transform to be applied to the neural network:
[1. 1.]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─Linear: 2-1                       [1, 64]                   192
│    └─LeakyReLU: 2-2                    [1, 64]                   --
│    └─Linear: 2-3                       [1, 64]                   4,160
│    └─LeakyReLU: 2-4                    [1, 64]                   --
│    └─Linear: 2-5                       [1, 64]                   4,160
│    └─LeakyReLU: 2-6                    [1, 64]                   --
│    └─Linear: 2-7                       [1, 64]                   4,160
│    └─LeakyReLU: 2-8                    [1, 64]                   --
│    └─Linear: 2-9                       [1, 64]                   4,160
│    └─LeakyReLU: 2-10                   [1, 64]                   --
│    └─Linear: 2-11                      [1, 64]                   4,160
│    └─LeakyReLU: 2-12                   [1, 64]                   --
│    └─Linear: 2-13                      [1, 64]                   4,160
│    └─LeakyReLU: 2-14                   [1, 64]                   --
│    └─Linear: 2-15                      [1, 2]                    130
==========================================================================================
Total params: 25,288
Trainable params: 25,282
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.03
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.10
Estimated Total Size (MB): 0.10
==========================================================================================
==> Saving initial model weights...
==> Start training...
Epoch: 001 | Loss: 19.3925887 | L2 loss: 19.3924915 | Lip loss: 0.0000971 | Grad norm: 0.886403 | Time: 7s468ms
Epoch: 001 | Test Loss: 18.4862433 | Time: 366ms
==> Save the model at epoch 001 with test loss 18.4862433
Epoch: 002 | Loss: 18.2514464 | L2 loss: 18.2496160 | Lip loss: 0.0018304 | Grad norm: 4.072472 | Time: 7s340ms
Epoch: 002 | Test Loss: 15.4230038 | Time: 358ms
==> Save the model at epoch 002 with test loss 15.4230038
Epoch: 003 | Loss: 9.8205338 | L2 loss: 9.8071098 | Lip loss: 0.0134241 | Grad norm: 14.827129 | Time: 7s40ms
Epoch: 003 | Test Loss: 1.9395003 | Time: 358ms
==> Save the model at epoch 003 with test loss 1.9395003
Epoch: 004 | Loss: 0.3783051 | L2 loss: 0.3515487 | Lip loss: 0.0267564 | Grad norm: 4.823416 | Time: 6s991ms
Epoch: 004 | Test Loss: 0.0663406 | Time: 379ms
==> Save the model at epoch 004 with test loss 0.0663406
Epoch: 005 | Loss: 0.0558494 | L2 loss: 0.0321967 | Lip loss: 0.0236528 | Grad norm: 2.187552 | Time: 7s98ms
Epoch: 005 | Test Loss: 0.0117328 | Time: 359ms
==> Save the model at epoch 005 with test loss 0.0117328
Epoch: 006 | Loss: 0.0321943 | L2 loss: 0.0101417 | Lip loss: 0.0220526 | Grad norm: 0.660351 | Time: 7s120ms
Epoch: 006 | Test Loss: 0.0095455 | Time: 440ms
==> Save the model at epoch 006 with test loss 0.0095455
Epoch: 007 | Loss: 0.0309171 | L2 loss: 0.0088571 | Lip loss: 0.0220601 | Grad norm: 0.527318 | Time: 6s999ms
Epoch: 007 | Test Loss: 0.0084364 | Time: 373ms
==> Save the model at epoch 007 with test loss 0.0084364
Epoch: 008 | Loss: 0.0298012 | L2 loss: 0.0079328 | Lip loss: 0.0218684 | Grad norm: 0.516789 | Time: 7s64ms
Epoch: 008 | Test Loss: 0.0075340 | Time: 364ms
==> Save the model at epoch 008 with test loss 0.0075340
Epoch: 009 | Loss: 0.0290861 | L2 loss: 0.0071911 | Lip loss: 0.0218950 | Grad norm: 0.461582 | Time: 7s79ms
Epoch: 009 | Test Loss: 0.0068265 | Time: 370ms
==> Save the model at epoch 009 with test loss 0.0068265
Epoch: 010 | Loss: 0.0282792 | L2 loss: 0.0065179 | Lip loss: 0.0217613 | Grad norm: 0.421023 | Time: 7s321ms
Epoch: 010 | Test Loss: 0.0062542 | Time: 382ms
==> Save the model at epoch 010 with test loss 0.0062542
Epoch: 011 | Loss: 0.0279595 | L2 loss: 0.0061838 | Lip loss: 0.0217757 | Grad norm: 0.386399 | Time: 7s159ms
Epoch: 011 | Test Loss: 0.0061845 | Time: 386ms
==> Save the model at epoch 011 with test loss 0.0061845
Epoch: 012 | Loss: 0.0277307 | L2 loss: 0.0061370 | Lip loss: 0.0215937 | Grad norm: 0.388970 | Time: 7s18ms
Epoch: 012 | Test Loss: 0.0061348 | Time: 366ms
==> Save the model at epoch 012 with test loss 0.0061348
Epoch: 013 | Loss: 0.0279373 | L2 loss: 0.0060945 | Lip loss: 0.0218428 | Grad norm: 0.353509 | Time: 6s777ms
Epoch: 013 | Test Loss: 0.0060723 | Time: 426ms
==> Save the model at epoch 013 with test loss 0.0060723
Epoch: 014 | Loss: 0.0276557 | L2 loss: 0.0060523 | Lip loss: 0.0216034 | Grad norm: 0.389375 | Time: 6s860ms
Epoch: 014 | Test Loss: 0.0060245 | Time: 367ms
==> Save the model at epoch 014 with test loss 0.0060245
Epoch: 015 | Loss: 0.0276873 | L2 loss: 0.0059802 | Lip loss: 0.0217071 | Grad norm: 0.371877 | Time: 6s793ms
Epoch: 015 | Test Loss: 0.0059544 | Time: 370ms
==> Save the model at epoch 015 with test loss 0.0059544
Epoch: 016 | Loss: 0.0277343 | L2 loss: 0.0059486 | Lip loss: 0.0217857 | Grad norm: 0.346933 | Time: 6s826ms
Epoch: 016 | Test Loss: 0.0059495 | Time: 365ms
==> Save the model at epoch 016 with test loss 0.0059495
Epoch: 017 | Loss: 0.0276311 | L2 loss: 0.0059270 | Lip loss: 0.0217041 | Grad norm: 0.336795 | Time: 7s85ms
Epoch: 017 | Test Loss: 0.0059433 | Time: 370ms
==> Save the model at epoch 017 with test loss 0.0059433
Epoch: 018 | Loss: 0.0277396 | L2 loss: 0.0059387 | Lip loss: 0.0218009 | Grad norm: 0.343154 | Time: 7s162ms
Epoch: 018 | Test Loss: 0.0059380 | Time: 366ms
==> Save the model at epoch 018 with test loss 0.0059380
Epoch: 019 | Loss: 0.0276676 | L2 loss: 0.0059246 | Lip loss: 0.0217430 | Grad norm: 0.350289 | Time: 7s549ms
Epoch: 019 | Test Loss: 0.0059315 | Time: 378ms
==> Save the model at epoch 019 with test loss 0.0059315
Epoch: 020 | Loss: 0.0278021 | L2 loss: 0.0059469 | Lip loss: 0.0218551 | Grad norm: 0.330086 | Time: 7s358ms
Epoch: 020 | Test Loss: 0.0059268 | Time: 377ms
==> Save the model at epoch 020 with test loss 0.0059268
Epoch: 021 | Loss: 0.0276244 | L2 loss: 0.0059085 | Lip loss: 0.0217159 | Grad norm: 0.315660 | Time: 7s216ms
Epoch: 021 | Test Loss: 0.0059264 | Time: 359ms
==> Save the model at epoch 021 with test loss 0.0059264
Epoch: 022 | Loss: 0.0275424 | L2 loss: 0.0059159 | Lip loss: 0.0216265 | Grad norm: 0.316439 | Time: 6s923ms
Epoch: 022 | Test Loss: 0.0059259 | Time: 378ms
==> Save the model at epoch 022 with test loss 0.0059259
Epoch: 023 | Loss: 0.0276674 | L2 loss: 0.0059247 | Lip loss: 0.0217427 | Grad norm: 0.332214 | Time: 6s952ms
Epoch: 023 | Test Loss: 0.0059254 | Time: 446ms
==> Save the model at epoch 023 with test loss 0.0059254
Epoch: 024 | Loss: 0.0275965 | L2 loss: 0.0058978 | Lip loss: 0.0216987 | Grad norm: 0.334805 | Time: 7s100ms
Epoch: 024 | Test Loss: 0.0059247 | Time: 360ms
==> Save the model at epoch 024 with test loss 0.0059247
Epoch: 025 | Loss: 0.0275185 | L2 loss: 0.0059011 | Lip loss: 0.0216174 | Grad norm: 0.356934 | Time: 6s999ms
Epoch: 025 | Test Loss: 0.0059243 | Time: 382ms
==> Save the model at epoch 025 with test loss 0.0059243
Epoch: 026 | Loss: 0.0276503 | L2 loss: 0.0058912 | Lip loss: 0.0217590 | Grad norm: 0.333918 | Time: 7s43ms
Epoch: 026 | Test Loss: 0.0059243 | Time: 367ms
==> Save the model at epoch 026 with test loss 0.0059243
Epoch: 027 | Loss: 0.0276677 | L2 loss: 0.0059087 | Lip loss: 0.0217590 | Grad norm: 0.332780 | Time: 7s75ms
Epoch: 027 | Test Loss: 0.0059243 | Time: 375ms
==> Save the model at epoch 027 with test loss 0.0059243
Epoch: 028 | Loss: 0.0275276 | L2 loss: 0.0058888 | Lip loss: 0.0216388 | Grad norm: 0.324077 | Time: 7s134ms
Epoch: 028 | Test Loss: 0.0059243 | Time: 362ms
==> Save the model at epoch 028 with test loss 0.0059243
Epoch: 029 | Loss: 0.0275146 | L2 loss: 0.0058976 | Lip loss: 0.0216171 | Grad norm: 0.335482 | Time: 6s809ms
Epoch: 029 | Test Loss: 0.0059243 | Time: 365ms
==> Save the model at epoch 029 with test loss 0.0059243
Epoch: 030 | Loss: 0.0275096 | L2 loss: 0.0059041 | Lip loss: 0.0216055 | Grad norm: 0.355051 | Time: 6s824ms
Epoch: 030 | Test Loss: 0.0059243 | Time: 427ms
==> Save the model at epoch 030 with test loss 0.0059243
Epoch: 031 | Loss: 0.0275987 | L2 loss: 0.0059394 | Lip loss: 0.0216594 | Grad norm: 0.327598 | Time: 6s902ms
Epoch: 031 | Test Loss: 0.0059243 | Time: 359ms
==> Save the model at epoch 031 with test loss 0.0059243
Epoch: 032 | Loss: 0.0276145 | L2 loss: 0.0059263 | Lip loss: 0.0216883 | Grad norm: 0.342863 | Time: 6s816ms
Epoch: 032 | Test Loss: 0.0059243 | Time: 360ms
Epoch: 033 | Loss: 0.0275718 | L2 loss: 0.0059337 | Lip loss: 0.0216381 | Grad norm: 0.349489 | Time: 6s964ms
Epoch: 033 | Test Loss: 0.0059243 | Time: 355ms
Epoch: 034 | Loss: 0.0277439 | L2 loss: 0.0059140 | Lip loss: 0.0218299 | Grad norm: 0.345918 | Time: 6s804ms
Epoch: 034 | Test Loss: 0.0059243 | Time: 366ms
Epoch: 035 | Loss: 0.0276177 | L2 loss: 0.0059121 | Lip loss: 0.0217056 | Grad norm: 0.336116 | Time: 6s803ms
Epoch: 035 | Test Loss: 0.0059243 | Time: 359ms
==> Save the model at epoch 035 with test loss 0.0059243
Epoch: 036 | Loss: 0.0276225 | L2 loss: 0.0059869 | Lip loss: 0.0216356 | Grad norm: 0.355250 | Time: 7s262ms
Epoch: 036 | Test Loss: 0.0059243 | Time: 369ms
Epoch: 037 | Loss: 0.0275542 | L2 loss: 0.0059192 | Lip loss: 0.0216350 | Grad norm: 0.352844 | Time: 7s8ms
Epoch: 037 | Test Loss: 0.0059243 | Time: 364ms
==> Save the model at epoch 037 with test loss 0.0059243
Epoch: 038 | Loss: 0.0276071 | L2 loss: 0.0059166 | Lip loss: 0.0216905 | Grad norm: 0.320845 | Time: 7s45ms
Epoch: 038 | Test Loss: 0.0059243 | Time: 356ms
Epoch: 039 | Loss: 0.0278032 | L2 loss: 0.0059363 | Lip loss: 0.0218669 | Grad norm: 0.367543 | Time: 6s838ms
Epoch: 039 | Test Loss: 0.0059243 | Time: 362ms
Epoch: 040 | Loss: 0.0275449 | L2 loss: 0.0059129 | Lip loss: 0.0216321 | Grad norm: 0.356601 | Time: 7s160ms
Epoch: 040 | Test Loss: 0.0059243 | Time: 363ms
Total time: 4m56s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[1. 1.]
==> Output transform to be applied to the neural network (trained):
[1. 1.]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Drawing l2 loss...
==> Drawing lip loss...
==> Process finished.
