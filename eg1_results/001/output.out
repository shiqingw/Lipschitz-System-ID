==> torch device:  cuda:0
==> Lipschitz constant: 1.00
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[0.5090095 0.5090095]
==> Ouput transform to be applied to the neural network:
[3.9366 3.9363]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─SandwichFc: 2-1                   [1, 128]                  16,897
│    └─SandwichFc: 2-2                   [1, 128]                  33,025
│    └─SandwichFc: 2-3                   [1, 128]                  33,025
│    └─SandwichFc: 2-4                   [1, 128]                  33,025
│    └─SandwichFc: 2-5                   [1, 128]                  33,025
│    └─SandwichFc: 2-6                   [1, 128]                  33,025
│    └─SandwichFc: 2-7                   [1, 128]                  33,025
│    └─SandwichLin: 2-8                  [1, 2]                    263
├─Sequential: 1-2                        [1, 2]                    (recursive)
│    └─SandwichFc: 2-9                   [1, 128]                  (recursive)
│    └─SandwichFc: 2-10                  [1, 128]                  (recursive)
│    └─SandwichFc: 2-11                  [1, 128]                  (recursive)
│    └─SandwichFc: 2-12                  [1, 128]                  (recursive)
│    └─SandwichFc: 2-13                  [1, 128]                  (recursive)
│    └─SandwichFc: 2-14                  [1, 128]                  (recursive)
│    └─SandwichFc: 2-15                  [1, 128]                  (recursive)
│    └─SandwichLin: 2-16                 [1, 2]                    (recursive)
==========================================================================================
Total params: 215,316
Trainable params: 215,310
Non-trainable params: 6
Total mult-adds (M): 0.43
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.86
Estimated Total Size (MB): 0.88
==========================================================================================
==> Saving initial model weights...
==> Test-Train split: test_ratio = 0.20
==> Further split: further_train_ratio = 0.25
==> Start training...
==> Number of param_groups in optimizer: 1
Epoch: 001 | Train Loss: 31.0142356 | Grad norm: 7.693652 | Time: 5s500ms
Epoch: 001 | Test Loss: 31.0111956 | Time: 754ms
==> Save the model at epoch 001 with test loss 31.0111956
Epoch: 002 | Train Loss: 13.8358050 | Grad norm: 17.918799 | Time: 5s499ms
Epoch: 002 | Test Loss: 6.5370107 | Time: 770ms
==> Save the model at epoch 002 with test loss 6.5370107
Epoch: 003 | Train Loss: 5.3852738 | Grad norm: 14.302383 | Time: 5s371ms
Epoch: 003 | Test Loss: 4.4894473 | Time: 759ms
==> Save the model at epoch 003 with test loss 4.4894473
Epoch: 004 | Train Loss: 3.5822383 | Grad norm: 10.692745 | Time: 5s387ms
Epoch: 004 | Test Loss: 2.7675797 | Time: 786ms
==> Save the model at epoch 004 with test loss 2.7675797
Epoch: 005 | Train Loss: 1.9822782 | Grad norm: 8.431511 | Time: 4s507ms
Epoch: 005 | Test Loss: 1.3791714 | Time: 757ms
==> Save the model at epoch 005 with test loss 1.3791714
Epoch: 006 | Train Loss: 1.1962375 | Grad norm: 18.475010 | Time: 4s318ms
Epoch: 006 | Test Loss: 1.0054119 | Time: 756ms
==> Save the model at epoch 006 with test loss 1.0054119
Epoch: 007 | Train Loss: 0.7544918 | Grad norm: 17.189623 | Time: 5s60ms
Epoch: 007 | Test Loss: 0.6442187 | Time: 819ms
==> Save the model at epoch 007 with test loss 0.6442187
Epoch: 008 | Train Loss: 0.5680444 | Grad norm: 17.992500 | Time: 4s999ms
Epoch: 008 | Test Loss: 0.4829908 | Time: 743ms
==> Save the model at epoch 008 with test loss 0.4829908
Epoch: 009 | Train Loss: 0.4377471 | Grad norm: 18.257339 | Time: 5s17ms
Epoch: 009 | Test Loss: 0.3925266 | Time: 747ms
==> Save the model at epoch 009 with test loss 0.3925266
Epoch: 010 | Train Loss: 0.3470266 | Grad norm: 18.384072 | Time: 5s514ms
Epoch: 010 | Test Loss: 0.3130648 | Time: 750ms
==> Save the model at epoch 010 with test loss 0.3130648
Epoch: 011 | Train Loss: 0.2827757 | Grad norm: 18.395641 | Time: 4s971ms
Epoch: 011 | Test Loss: 0.2690747 | Time: 808ms
==> Save the model at epoch 011 with test loss 0.2690747
Epoch: 012 | Train Loss: 0.2186799 | Grad norm: 16.692846 | Time: 5s24ms
Epoch: 012 | Test Loss: 0.1949414 | Time: 761ms
==> Save the model at epoch 012 with test loss 0.1949414
Epoch: 013 | Train Loss: 0.1730698 | Grad norm: 15.259272 | Time: 5s27ms
Epoch: 013 | Test Loss: 0.1698700 | Time: 744ms
==> Save the model at epoch 013 with test loss 0.1698700
Epoch: 014 | Train Loss: 0.1406667 | Grad norm: 14.074958 | Time: 5s22ms
Epoch: 014 | Test Loss: 0.1322857 | Time: 753ms
==> Save the model at epoch 014 with test loss 0.1322857
Epoch: 015 | Train Loss: 0.1166202 | Grad norm: 13.037241 | Time: 4s952ms
Epoch: 015 | Test Loss: 0.1179216 | Time: 758ms
==> Save the model at epoch 015 with test loss 0.1179216
Epoch: 016 | Train Loss: 0.0987424 | Grad norm: 12.110421 | Time: 4s322ms
Epoch: 016 | Test Loss: 0.0989421 | Time: 758ms
==> Save the model at epoch 016 with test loss 0.0989421
Epoch: 017 | Train Loss: 0.0844886 | Grad norm: 11.252212 | Time: 4s393ms
Epoch: 017 | Test Loss: 0.0864463 | Time: 752ms
==> Save the model at epoch 017 with test loss 0.0864463
Epoch: 018 | Train Loss: 0.0737115 | Grad norm: 10.553910 | Time: 4s475ms
Epoch: 018 | Test Loss: 0.0747311 | Time: 756ms
==> Save the model at epoch 018 with test loss 0.0747311
Epoch: 019 | Train Loss: 0.0651606 | Grad norm: 9.929098 | Time: 4s379ms
Epoch: 019 | Test Loss: 0.0646581 | Time: 758ms
==> Save the model at epoch 019 with test loss 0.0646581
Epoch: 020 | Train Loss: 0.0577452 | Grad norm: 9.318314 | Time: 4s810ms
Epoch: 020 | Test Loss: 0.0599371 | Time: 753ms
==> Save the model at epoch 020 with test loss 0.0599371
Epoch: 021 | Train Loss: 0.0513957 | Grad norm: 8.739453 | Time: 5s580ms
Epoch: 021 | Test Loss: 0.0520768 | Time: 1s23ms
==> Save the model at epoch 021 with test loss 0.0520768
Epoch: 022 | Train Loss: 0.0461673 | Grad norm: 8.239202 | Time: 5s604ms
Epoch: 022 | Test Loss: 0.0480304 | Time: 1s40ms
==> Save the model at epoch 022 with test loss 0.0480304
Epoch: 023 | Train Loss: 0.0415955 | Grad norm: 7.758556 | Time: 5s456ms
Epoch: 023 | Test Loss: 0.0421420 | Time: 769ms
==> Save the model at epoch 023 with test loss 0.0421420
Epoch: 024 | Train Loss: 0.0375510 | Grad norm: 7.307819 | Time: 5s193ms
Epoch: 024 | Test Loss: 0.0383386 | Time: 755ms
==> Save the model at epoch 024 with test loss 0.0383386
Epoch: 025 | Train Loss: 0.0340297 | Grad norm: 6.881693 | Time: 5s110ms
Epoch: 025 | Test Loss: 0.0357286 | Time: 795ms
==> Save the model at epoch 025 with test loss 0.0357286
Epoch: 026 | Train Loss: 0.0311845 | Grad norm: 6.522605 | Time: 5s943ms
Epoch: 026 | Test Loss: 0.0313923 | Time: 830ms
==> Save the model at epoch 026 with test loss 0.0313923
Epoch: 027 | Train Loss: 0.0283585 | Grad norm: 6.139705 | Time: 5s38ms
Epoch: 027 | Test Loss: 0.0296222 | Time: 759ms
==> Save the model at epoch 027 with test loss 0.0296222
Epoch: 028 | Train Loss: 0.0261035 | Grad norm: 5.813848 | Time: 4s995ms
Epoch: 028 | Test Loss: 0.0263920 | Time: 745ms
==> Save the model at epoch 028 with test loss 0.0263920
Epoch: 029 | Train Loss: 0.0240553 | Grad norm: 5.499457 | Time: 5s32ms
Epoch: 029 | Test Loss: 0.0250313 | Time: 758ms
==> Save the model at epoch 029 with test loss 0.0250313
Epoch: 030 | Train Loss: 0.0218751 | Grad norm: 5.116910 | Time: 5s71ms
Epoch: 030 | Test Loss: 0.0222932 | Time: 745ms
==> Save the model at epoch 030 with test loss 0.0222932
Epoch: 031 | Train Loss: 0.0203860 | Grad norm: 4.868440 | Time: 4s995ms
Epoch: 031 | Test Loss: 0.0212663 | Time: 743ms
==> Save the model at epoch 031 with test loss 0.0212663
Epoch: 032 | Train Loss: 0.0187992 | Grad norm: 4.565546 | Time: 5s27ms
Epoch: 032 | Test Loss: 0.0185457 | Time: 755ms
==> Save the model at epoch 032 with test loss 0.0185457
Epoch: 033 | Train Loss: 0.0172952 | Grad norm: 4.260314 | Time: 5s15ms
Epoch: 033 | Test Loss: 0.0184218 | Time: 814ms
==> Save the model at epoch 033 with test loss 0.0184218
Epoch: 034 | Train Loss: 0.0162252 | Grad norm: 4.022778 | Time: 5s97ms
Epoch: 034 | Test Loss: 0.0155946 | Time: 756ms
==> Save the model at epoch 034 with test loss 0.0155946
Epoch: 035 | Train Loss: 0.0150602 | Grad norm: 3.762596 | Time: 4s997ms
Epoch: 035 | Test Loss: 0.0160136 | Time: 741ms
Epoch: 036 | Train Loss: 0.0141580 | Grad norm: 3.533561 | Time: 5s21ms
Epoch: 036 | Test Loss: 0.0137845 | Time: 756ms
==> Save the model at epoch 036 with test loss 0.0137845
Epoch: 037 | Train Loss: 0.0130085 | Grad norm: 3.222440 | Time: 5s26ms
Epoch: 037 | Test Loss: 0.0139290 | Time: 817ms
Epoch: 038 | Train Loss: 0.0122867 | Grad norm: 3.007383 | Time: 5s99ms
Epoch: 038 | Test Loss: 0.0119903 | Time: 758ms
==> Save the model at epoch 038 with test loss 0.0119903
Epoch: 039 | Train Loss: 0.0116287 | Grad norm: 2.817470 | Time: 5s125ms
Epoch: 039 | Test Loss: 0.0121786 | Time: 756ms
Epoch: 040 | Train Loss: 0.0109588 | Grad norm: 2.576320 | Time: 5s420ms
Epoch: 040 | Test Loss: 0.0106637 | Time: 749ms
==> Save the model at epoch 040 with test loss 0.0106637
Epoch: 041 | Train Loss: 0.0103646 | Grad norm: 2.371400 | Time: 5s207ms
Epoch: 041 | Test Loss: 0.0108267 | Time: 755ms
Epoch: 042 | Train Loss: 0.0098538 | Grad norm: 2.157226 | Time: 5s11ms
Epoch: 042 | Test Loss: 0.0098235 | Time: 773ms
==> Save the model at epoch 042 with test loss 0.0098235
Epoch: 043 | Train Loss: 0.0094478 | Grad norm: 1.988215 | Time: 5s
Epoch: 043 | Test Loss: 0.0096457 | Time: 748ms
==> Save the model at epoch 043 with test loss 0.0096457
Epoch: 044 | Train Loss: 0.0088373 | Grad norm: 1.546109 | Time: 5s24ms
Epoch: 044 | Test Loss: 0.0079747 | Time: 815ms
==> Save the model at epoch 044 with test loss 0.0079747
Epoch: 045 | Train Loss: 0.0183517 | Grad norm: 4.365777 | Time: 5s7ms
Epoch: 045 | Test Loss: 0.0327680 | Time: 749ms
Epoch: 046 | Train Loss: 0.0168165 | Grad norm: 4.133302 | Time: 5s68ms
Epoch: 046 | Test Loss: 0.0088252 | Time: 769ms
Epoch: 047 | Train Loss: 0.0148209 | Grad norm: 3.691230 | Time: 5s30ms
Epoch: 047 | Test Loss: 0.0196146 | Time: 741ms
Epoch: 048 | Train Loss: 0.0095173 | Grad norm: 1.810460 | Time: 5s545ms
Epoch: 048 | Test Loss: 0.0079672 | Time: 827ms
==> Save the model at epoch 048 with test loss 0.0079672
Epoch: 049 | Train Loss: 0.0077832 | Grad norm: 0.730542 | Time: 4s964ms
Epoch: 049 | Test Loss: 0.0077915 | Time: 752ms
==> Save the model at epoch 049 with test loss 0.0077915
Epoch: 050 | Train Loss: 0.0075600 | Grad norm: 0.579375 | Time: 4s411ms
Epoch: 050 | Test Loss: 0.0075573 | Time: 759ms
==> Save the model at epoch 050 with test loss 0.0075573
Epoch: 051 | Train Loss: 0.0075881 | Grad norm: 0.604910 | Time: 4s331ms
Epoch: 051 | Test Loss: 0.0074560 | Time: 757ms
==> Save the model at epoch 051 with test loss 0.0074560
Epoch: 052 | Train Loss: 0.0074207 | Grad norm: 0.417591 | Time: 4s379ms
Epoch: 052 | Test Loss: 0.0074603 | Time: 753ms
Epoch: 053 | Train Loss: 0.0074409 | Grad norm: 0.474117 | Time: 4s317ms
Epoch: 053 | Test Loss: 0.0077062 | Time: 758ms
Epoch: 054 | Train Loss: 0.0074310 | Grad norm: 0.421589 | Time: 4s325ms
Epoch: 054 | Test Loss: 0.0074602 | Time: 754ms
Epoch: 055 | Train Loss: 0.0073281 | Grad norm: 0.285805 | Time: 4s319ms
Epoch: 055 | Test Loss: 0.0076886 | Time: 757ms
Epoch: 056 | Train Loss: 0.0073121 | Grad norm: 0.277594 | Time: 4s385ms
Epoch: 056 | Test Loss: 0.0074018 | Time: 756ms
==> Save the model at epoch 056 with test loss 0.0074018
Epoch: 057 | Train Loss: 0.0073101 | Grad norm: 0.274722 | Time: 4s313ms
Epoch: 057 | Test Loss: 0.0074020 | Time: 764ms
Epoch: 058 | Train Loss: 0.0072843 | Grad norm: 0.204707 | Time: 4s324ms
Epoch: 058 | Test Loss: 0.0073998 | Time: 763ms
==> Save the model at epoch 058 with test loss 0.0073998
Epoch: 059 | Train Loss: 0.0072712 | Grad norm: 0.153862 | Time: 4s961ms
Epoch: 059 | Test Loss: 0.0074137 | Time: 901ms
Epoch: 060 | Train Loss: 0.0072728 | Grad norm: 0.157371 | Time: 4s812ms
Epoch: 060 | Test Loss: 0.0073974 | Time: 801ms
==> Save the model at epoch 060 with test loss 0.0073974
Total time: 5m43s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[0.5090095 0.5090095]
==> Output transform to be applied to the neural network (trained):
[3.9366 3.9363]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Process finished.
