==> torch device:  cuda:0
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.25
==> Further split seed:  None
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[1. 1.]
==> Ouput transform to be applied to the neural network:
[1. 1.]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─Linear: 2-1                       [1, 64]                   192
│    └─LeakyReLU: 2-2                    [1, 64]                   --
│    └─Linear: 2-3                       [1, 64]                   4,160
│    └─LeakyReLU: 2-4                    [1, 64]                   --
│    └─Linear: 2-5                       [1, 64]                   4,160
│    └─LeakyReLU: 2-6                    [1, 64]                   --
│    └─Linear: 2-7                       [1, 64]                   4,160
│    └─LeakyReLU: 2-8                    [1, 64]                   --
│    └─Linear: 2-9                       [1, 64]                   4,160
│    └─LeakyReLU: 2-10                   [1, 64]                   --
│    └─Linear: 2-11                      [1, 64]                   4,160
│    └─LeakyReLU: 2-12                   [1, 64]                   --
│    └─Linear: 2-13                      [1, 64]                   4,160
│    └─LeakyReLU: 2-14                   [1, 64]                   --
│    └─Linear: 2-15                      [1, 2]                    130
==========================================================================================
Total params: 25,288
Trainable params: 25,282
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.03
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.10
Estimated Total Size (MB): 0.10
==========================================================================================
==> Saving initial model weights...
==> Start training...
Epoch: 001 | Loss: 18.8576505 | L2 loss: 18.8576505 | Lip loss: 0.0000000 | Grad norm: 0.931297 | Time: 7s116ms
Epoch: 001 | Test Loss: 18.5681165 | Time: 355ms
==> Save the model at epoch 001 with test loss 18.5681165
Epoch: 002 | Loss: 17.5016971 | L2 loss: 17.5016970 | Lip loss: 0.0000002 | Grad norm: 4.070770 | Time: 6s880ms
Epoch: 002 | Test Loss: 15.4488290 | Time: 364ms
==> Save the model at epoch 002 with test loss 15.4488290
Epoch: 003 | Loss: 10.9466406 | L2 loss: 10.9466391 | Lip loss: 0.0000015 | Grad norm: 11.000063 | Time: 6s923ms
Epoch: 003 | Test Loss: 6.3081832 | Time: 363ms
==> Save the model at epoch 003 with test loss 6.3081832
Epoch: 004 | Loss: 2.6228217 | L2 loss: 2.6228192 | Lip loss: 0.0000025 | Grad norm: 7.822239 | Time: 7s36ms
Epoch: 004 | Test Loss: 0.0849928 | Time: 368ms
==> Save the model at epoch 004 with test loss 0.0849928
Epoch: 005 | Loss: 0.0336583 | L2 loss: 0.0336559 | Lip loss: 0.0000023 | Grad norm: 2.336756 | Time: 7s562ms
Epoch: 005 | Test Loss: 0.0178635 | Time: 361ms
==> Save the model at epoch 005 with test loss 0.0178635
Epoch: 006 | Loss: 0.0145545 | L2 loss: 0.0145522 | Lip loss: 0.0000022 | Grad norm: 0.827993 | Time: 7s226ms
Epoch: 006 | Test Loss: 0.0137198 | Time: 442ms
==> Save the model at epoch 006 with test loss 0.0137198
Epoch: 007 | Loss: 0.0129116 | L2 loss: 0.0129093 | Lip loss: 0.0000022 | Grad norm: 0.616998 | Time: 7s14ms
Epoch: 007 | Test Loss: 0.0124534 | Time: 364ms
==> Save the model at epoch 007 with test loss 0.0124534
Epoch: 008 | Loss: 0.0117634 | L2 loss: 0.0117612 | Lip loss: 0.0000022 | Grad norm: 0.548635 | Time: 6s841ms
Epoch: 008 | Test Loss: 0.0113246 | Time: 363ms
==> Save the model at epoch 008 with test loss 0.0113246
Epoch: 009 | Loss: 0.0108648 | L2 loss: 0.0108626 | Lip loss: 0.0000022 | Grad norm: 0.650933 | Time: 7s37ms
Epoch: 009 | Test Loss: 0.0104793 | Time: 354ms
==> Save the model at epoch 009 with test loss 0.0104793
Epoch: 010 | Loss: 0.0100284 | L2 loss: 0.0100262 | Lip loss: 0.0000022 | Grad norm: 0.552114 | Time: 7s39ms
Epoch: 010 | Test Loss: 0.0097531 | Time: 362ms
==> Save the model at epoch 010 with test loss 0.0097531
Epoch: 011 | Loss: 0.0096230 | L2 loss: 0.0096208 | Lip loss: 0.0000022 | Grad norm: 0.439752 | Time: 6s876ms
Epoch: 011 | Test Loss: 0.0096621 | Time: 360ms
==> Save the model at epoch 011 with test loss 0.0096621
Epoch: 012 | Loss: 0.0095434 | L2 loss: 0.0095412 | Lip loss: 0.0000022 | Grad norm: 0.420240 | Time: 6s853ms
Epoch: 012 | Test Loss: 0.0095882 | Time: 361ms
==> Save the model at epoch 012 with test loss 0.0095882
Epoch: 013 | Loss: 0.0094737 | L2 loss: 0.0094715 | Lip loss: 0.0000022 | Grad norm: 0.393378 | Time: 6s907ms
Epoch: 013 | Test Loss: 0.0095157 | Time: 436ms
==> Save the model at epoch 013 with test loss 0.0095157
Epoch: 014 | Loss: 0.0094273 | L2 loss: 0.0094252 | Lip loss: 0.0000022 | Grad norm: 0.417300 | Time: 6s902ms
Epoch: 014 | Test Loss: 0.0094565 | Time: 375ms
==> Save the model at epoch 014 with test loss 0.0094565
Epoch: 015 | Loss: 0.0093324 | L2 loss: 0.0093303 | Lip loss: 0.0000022 | Grad norm: 0.446285 | Time: 7s92ms
Epoch: 015 | Test Loss: 0.0094013 | Time: 356ms
==> Save the model at epoch 015 with test loss 0.0094013
Epoch: 016 | Loss: 0.0092693 | L2 loss: 0.0092671 | Lip loss: 0.0000022 | Grad norm: 0.381541 | Time: 6s913ms
Epoch: 016 | Test Loss: 0.0093756 | Time: 364ms
==> Save the model at epoch 016 with test loss 0.0093756
Epoch: 017 | Loss: 0.0092700 | L2 loss: 0.0092678 | Lip loss: 0.0000022 | Grad norm: 0.411235 | Time: 7s120ms
Epoch: 017 | Test Loss: 0.0093688 | Time: 365ms
==> Save the model at epoch 017 with test loss 0.0093688
Epoch: 018 | Loss: 0.0092866 | L2 loss: 0.0092845 | Lip loss: 0.0000022 | Grad norm: 0.376554 | Time: 6s928ms
Epoch: 018 | Test Loss: 0.0093613 | Time: 361ms
==> Save the model at epoch 018 with test loss 0.0093613
Epoch: 019 | Loss: 0.0092734 | L2 loss: 0.0092713 | Lip loss: 0.0000022 | Grad norm: 0.406383 | Time: 6s878ms
Epoch: 019 | Test Loss: 0.0093542 | Time: 371ms
==> Save the model at epoch 019 with test loss 0.0093542
Epoch: 020 | Loss: 0.0092881 | L2 loss: 0.0092860 | Lip loss: 0.0000021 | Grad norm: 0.458634 | Time: 6s866ms
Epoch: 020 | Test Loss: 0.0093470 | Time: 363ms
==> Save the model at epoch 020 with test loss 0.0093470
Epoch: 021 | Loss: 0.0092313 | L2 loss: 0.0092291 | Lip loss: 0.0000022 | Grad norm: 0.390526 | Time: 6s874ms
Epoch: 021 | Test Loss: 0.0093464 | Time: 356ms
==> Save the model at epoch 021 with test loss 0.0093464
Epoch: 022 | Loss: 0.0092498 | L2 loss: 0.0092476 | Lip loss: 0.0000022 | Grad norm: 0.412185 | Time: 6s845ms
Epoch: 022 | Test Loss: 0.0093458 | Time: 360ms
==> Save the model at epoch 022 with test loss 0.0093458
Epoch: 023 | Loss: 0.0092589 | L2 loss: 0.0092567 | Lip loss: 0.0000022 | Grad norm: 0.339737 | Time: 6s833ms
Epoch: 023 | Test Loss: 0.0093452 | Time: 436ms
==> Save the model at epoch 023 with test loss 0.0093452
Epoch: 024 | Loss: 0.0092640 | L2 loss: 0.0092618 | Lip loss: 0.0000022 | Grad norm: 0.386285 | Time: 6s858ms
Epoch: 024 | Test Loss: 0.0093447 | Time: 366ms
==> Save the model at epoch 024 with test loss 0.0093447
Epoch: 025 | Loss: 0.0092491 | L2 loss: 0.0092470 | Lip loss: 0.0000022 | Grad norm: 0.388563 | Time: 6s830ms
Epoch: 025 | Test Loss: 0.0093440 | Time: 361ms
==> Save the model at epoch 025 with test loss 0.0093440
Epoch: 026 | Loss: 0.0092534 | L2 loss: 0.0092512 | Lip loss: 0.0000022 | Grad norm: 0.422989 | Time: 6s976ms
Epoch: 026 | Test Loss: 0.0093440 | Time: 376ms
==> Save the model at epoch 026 with test loss 0.0093440
Epoch: 027 | Loss: 0.0092532 | L2 loss: 0.0092511 | Lip loss: 0.0000022 | Grad norm: 0.411187 | Time: 6s961ms
Epoch: 027 | Test Loss: 0.0093440 | Time: 362ms
==> Save the model at epoch 027 with test loss 0.0093440
Epoch: 028 | Loss: 0.0092548 | L2 loss: 0.0092527 | Lip loss: 0.0000022 | Grad norm: 0.405894 | Time: 6s873ms
Epoch: 028 | Test Loss: 0.0093440 | Time: 368ms
==> Save the model at epoch 028 with test loss 0.0093440
Epoch: 029 | Loss: 0.0092206 | L2 loss: 0.0092185 | Lip loss: 0.0000021 | Grad norm: 0.390188 | Time: 6s931ms
Epoch: 029 | Test Loss: 0.0093440 | Time: 365ms
==> Save the model at epoch 029 with test loss 0.0093440
Epoch: 030 | Loss: 0.0092833 | L2 loss: 0.0092812 | Lip loss: 0.0000022 | Grad norm: 0.413605 | Time: 6s757ms
Epoch: 030 | Test Loss: 0.0093440 | Time: 432ms
==> Save the model at epoch 030 with test loss 0.0093440
Epoch: 031 | Loss: 0.0092348 | L2 loss: 0.0092326 | Lip loss: 0.0000022 | Grad norm: 0.380560 | Time: 6s965ms
Epoch: 031 | Test Loss: 0.0093440 | Time: 360ms
==> Save the model at epoch 031 with test loss 0.0093440
Epoch: 032 | Loss: 0.0092595 | L2 loss: 0.0092573 | Lip loss: 0.0000022 | Grad norm: 0.415401 | Time: 6s934ms
Epoch: 032 | Test Loss: 0.0093440 | Time: 360ms
Epoch: 033 | Loss: 0.0092523 | L2 loss: 0.0092502 | Lip loss: 0.0000022 | Grad norm: 0.389620 | Time: 6s861ms
Epoch: 033 | Test Loss: 0.0093440 | Time: 364ms
==> Save the model at epoch 033 with test loss 0.0093440
Epoch: 034 | Loss: 0.0092249 | L2 loss: 0.0092228 | Lip loss: 0.0000022 | Grad norm: 0.402249 | Time: 6s853ms
Epoch: 034 | Test Loss: 0.0093440 | Time: 361ms
==> Save the model at epoch 034 with test loss 0.0093440
Epoch: 035 | Loss: 0.0092461 | L2 loss: 0.0092439 | Lip loss: 0.0000022 | Grad norm: 0.384610 | Time: 6s967ms
Epoch: 035 | Test Loss: 0.0093440 | Time: 354ms
==> Save the model at epoch 035 with test loss 0.0093440
Epoch: 036 | Loss: 0.0092939 | L2 loss: 0.0092917 | Lip loss: 0.0000022 | Grad norm: 0.403803 | Time: 6s848ms
Epoch: 036 | Test Loss: 0.0093440 | Time: 359ms
Epoch: 037 | Loss: 0.0092677 | L2 loss: 0.0092656 | Lip loss: 0.0000022 | Grad norm: 0.397768 | Time: 6s811ms
Epoch: 037 | Test Loss: 0.0093440 | Time: 367ms
==> Save the model at epoch 037 with test loss 0.0093440
Epoch: 038 | Loss: 0.0092410 | L2 loss: 0.0092389 | Lip loss: 0.0000022 | Grad norm: 0.389789 | Time: 6s714ms
Epoch: 038 | Test Loss: 0.0093440 | Time: 372ms
Epoch: 039 | Loss: 0.0092509 | L2 loss: 0.0092487 | Lip loss: 0.0000022 | Grad norm: 0.383187 | Time: 6s885ms
Epoch: 039 | Test Loss: 0.0093440 | Time: 370ms
==> Save the model at epoch 039 with test loss 0.0093440
Epoch: 040 | Loss: 0.0092476 | L2 loss: 0.0092454 | Lip loss: 0.0000022 | Grad norm: 0.373303 | Time: 6s907ms
Epoch: 040 | Test Loss: 0.0093440 | Time: 366ms
Total time: 4m52s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[1. 1.]
==> Output transform to be applied to the neural network (trained):
[1. 1.]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Drawing l2 loss...
==> Drawing lip loss...
==> Process finished.
