==> torch device:  cuda:3
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 1.00
==> Further split seed:  None
==> Lipschitz constant: 16.00
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[0.6219679 0.6219679]
==> Ouput transform to be applied to the neural network:
[3.225  3.2249]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─SandwichFc: 2-1                   [1, 64]                   4,353
│    └─SandwichFc: 2-2                   [1, 64]                   8,321
│    └─SandwichFc: 2-3                   [1, 64]                   8,321
│    └─SandwichFc: 2-4                   [1, 64]                   8,321
│    └─SandwichFc: 2-5                   [1, 64]                   8,321
│    └─SandwichFc: 2-6                   [1, 64]                   8,321
│    └─SandwichFc: 2-7                   [1, 64]                   8,321
│    └─SandwichLin: 2-8                  [1, 2]                    135
├─Sequential: 1-2                        [1, 2]                    (recursive)
│    └─SandwichFc: 2-9                   [1, 64]                   (recursive)
│    └─SandwichFc: 2-10                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-11                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-12                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-13                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-14                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-15                  [1, 64]                   (recursive)
│    └─SandwichLin: 2-16                 [1, 2]                    (recursive)
==========================================================================================
Total params: 54,420
Trainable params: 54,414
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.11
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.22
Estimated Total Size (MB): 0.22
==========================================================================================
==> Saving initial model weights...
==> Start training...
==> Number of param_groups in optimizer: 1
Epoch: 001 | Train Loss: 19.6570529 | Grad norm: 89.463383 | Time: 19s843ms
Epoch: 001 | Test Loss: 19.5673763 | Time: 733ms
==> Save the model at epoch 001 with test loss 19.5673763
Epoch: 002 | Train Loss: 0.4319541 | Grad norm: 8.396365 | Time: 19s669ms
Epoch: 002 | Test Loss: 0.0054912 | Time: 675ms
==> Save the model at epoch 002 with test loss 0.0054912
Epoch: 003 | Train Loss: 0.0115964 | Grad norm: 5.682122 | Time: 20s24ms
Epoch: 003 | Test Loss: 0.0058033 | Time: 676ms
Epoch: 004 | Train Loss: 0.0182330 | Grad norm: 6.840787 | Time: 19s943ms
Epoch: 004 | Test Loss: 0.0139561 | Time: 666ms
Epoch: 005 | Train Loss: 0.0242293 | Grad norm: 7.791236 | Time: 20s221ms
Epoch: 005 | Test Loss: 0.0260374 | Time: 732ms
Epoch: 006 | Train Loss: 0.0295781 | Grad norm: 7.900478 | Time: 20s173ms
Epoch: 006 | Test Loss: 0.0438224 | Time: 663ms
Epoch: 007 | Train Loss: 0.0355470 | Grad norm: 9.062911 | Time: 19s551ms
Epoch: 007 | Test Loss: 0.0209687 | Time: 809ms
Epoch: 008 | Train Loss: 0.0365650 | Grad norm: 8.369829 | Time: 20s349ms
Epoch: 008 | Test Loss: 0.0567411 | Time: 670ms
Epoch: 009 | Train Loss: 0.0343451 | Grad norm: 8.534314 | Time: 20s274ms
Epoch: 009 | Test Loss: 0.0302964 | Time: 665ms
Epoch: 010 | Train Loss: 0.0292063 | Grad norm: 7.257333 | Time: 20s411ms
Epoch: 010 | Test Loss: 0.0308884 | Time: 663ms
Epoch: 011 | Train Loss: 0.0231482 | Grad norm: 6.421635 | Time: 19s861ms
Epoch: 011 | Test Loss: 0.0204183 | Time: 666ms
Epoch: 012 | Train Loss: 0.0196662 | Grad norm: 5.724208 | Time: 20s361ms
Epoch: 012 | Test Loss: 0.0191557 | Time: 664ms
Epoch: 013 | Train Loss: 0.0186792 | Grad norm: 5.279202 | Time: 20s130ms
Epoch: 013 | Test Loss: 0.0111131 | Time: 664ms
Epoch: 014 | Train Loss: 0.0162040 | Grad norm: 4.638482 | Time: 20s694ms
Epoch: 014 | Test Loss: 0.0148992 | Time: 735ms
Epoch: 015 | Train Loss: 0.0134815 | Grad norm: 4.546730 | Time: 20s307ms
Epoch: 015 | Test Loss: 0.0126224 | Time: 672ms
Epoch: 016 | Train Loss: 0.0131238 | Grad norm: 4.162234 | Time: 20s594ms
Epoch: 016 | Test Loss: 0.0107195 | Time: 663ms
Epoch: 017 | Train Loss: 0.0109370 | Grad norm: 3.903408 | Time: 19s828ms
Epoch: 017 | Test Loss: 0.0111123 | Time: 680ms
Epoch: 018 | Train Loss: 0.0099496 | Grad norm: 3.540812 | Time: 20s285ms
Epoch: 018 | Test Loss: 0.0074490 | Time: 661ms
Epoch: 019 | Train Loss: 0.0086911 | Grad norm: 3.337104 | Time: 19s818ms
Epoch: 019 | Test Loss: 0.0078854 | Time: 658ms
Epoch: 020 | Train Loss: 0.0074734 | Grad norm: 3.059645 | Time: 20s18ms
Epoch: 020 | Test Loss: 0.0069119 | Time: 663ms
Epoch: 021 | Train Loss: 0.0075706 | Grad norm: 2.711611 | Time: 19s898ms
Epoch: 021 | Test Loss: 0.0069010 | Time: 663ms
Epoch: 022 | Train Loss: 0.0062654 | Grad norm: 2.649002 | Time: 19s882ms
Epoch: 022 | Test Loss: 0.0047556 | Time: 693ms
==> Save the model at epoch 022 with test loss 0.0047556
Epoch: 023 | Train Loss: 0.0074216 | Grad norm: 2.628752 | Time: 19s911ms
Epoch: 023 | Test Loss: 0.0074359 | Time: 741ms
Epoch: 024 | Train Loss: 0.0055592 | Grad norm: 2.291999 | Time: 19s746ms
Epoch: 024 | Test Loss: 0.0059071 | Time: 662ms
Epoch: 025 | Train Loss: 0.0049556 | Grad norm: 2.014773 | Time: 20s118ms
Epoch: 025 | Test Loss: 0.0058162 | Time: 671ms
Epoch: 026 | Train Loss: 0.0043983 | Grad norm: 1.657021 | Time: 20s424ms
Epoch: 026 | Test Loss: 0.0041542 | Time: 665ms
==> Save the model at epoch 026 with test loss 0.0041542
Epoch: 027 | Train Loss: 0.0041045 | Grad norm: 1.523278 | Time: 19s675ms
Epoch: 027 | Test Loss: 0.0038058 | Time: 666ms
==> Save the model at epoch 027 with test loss 0.0038058
Epoch: 028 | Train Loss: 0.0037914 | Grad norm: 1.315459 | Time: 19s833ms
Epoch: 028 | Test Loss: 0.0033556 | Time: 667ms
==> Save the model at epoch 028 with test loss 0.0033556
Epoch: 029 | Train Loss: 0.0033942 | Grad norm: 0.969402 | Time: 20s39ms
Epoch: 029 | Test Loss: 0.0037190 | Time: 663ms
Epoch: 030 | Train Loss: 0.0037459 | Grad norm: 1.284990 | Time: 20s298ms
Epoch: 030 | Test Loss: 0.0033023 | Time: 675ms
==> Save the model at epoch 030 with test loss 0.0033023
Epoch: 031 | Train Loss: 0.0031268 | Grad norm: 0.761365 | Time: 19s875ms
Epoch: 031 | Test Loss: 0.0031570 | Time: 663ms
==> Save the model at epoch 031 with test loss 0.0031570
Epoch: 032 | Train Loss: 0.0029795 | Grad norm: 0.617130 | Time: 19s969ms
Epoch: 032 | Test Loss: 0.0029312 | Time: 736ms
==> Save the model at epoch 032 with test loss 0.0029312
Epoch: 033 | Train Loss: 0.0029358 | Grad norm: 0.555839 | Time: 19s871ms
Epoch: 033 | Test Loss: 0.0030026 | Time: 665ms
Epoch: 034 | Train Loss: 0.0028854 | Grad norm: 0.519581 | Time: 19s699ms
Epoch: 034 | Test Loss: 0.0029362 | Time: 674ms
Epoch: 035 | Train Loss: 0.0028548 | Grad norm: 0.490561 | Time: 20s24ms
Epoch: 035 | Test Loss: 0.0028420 | Time: 659ms
==> Save the model at epoch 035 with test loss 0.0028420
Epoch: 036 | Train Loss: 0.0028052 | Grad norm: 0.399046 | Time: 20s13ms
Epoch: 036 | Test Loss: 0.0028074 | Time: 735ms
==> Save the model at epoch 036 with test loss 0.0028074
Epoch: 037 | Train Loss: 0.0027724 | Grad norm: 0.376751 | Time: 20s189ms
Epoch: 037 | Test Loss: 0.0027607 | Time: 677ms
==> Save the model at epoch 037 with test loss 0.0027607
Epoch: 038 | Train Loss: 0.0027329 | Grad norm: 0.285991 | Time: 19s623ms
Epoch: 038 | Test Loss: 0.0027478 | Time: 661ms
==> Save the model at epoch 038 with test loss 0.0027478
Epoch: 039 | Train Loss: 0.0027117 | Grad norm: 0.247542 | Time: 20s115ms
Epoch: 039 | Test Loss: 0.0027397 | Time: 665ms
==> Save the model at epoch 039 with test loss 0.0027397
Epoch: 040 | Train Loss: 0.0026987 | Grad norm: 0.213308 | Time: 19s975ms
Epoch: 040 | Test Loss: 0.0027228 | Time: 666ms
==> Save the model at epoch 040 with test loss 0.0027228
Total time: 13m48s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[0.6219679 0.6219679]
==> Output transform to be applied to the neural network (trained):
[3.225  3.2249]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Process finished.
