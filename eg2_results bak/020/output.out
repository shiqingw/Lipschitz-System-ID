==> torch device:  cuda:3
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.25
==> Further split seed:  None
==> Lipschitz constant: 8.00
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[0.48014596 0.48395684]
==> Ouput transform to be applied to the neural network:
[2.0663 2.0805]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─SandwichFc: 2-1                   [1, 64]                   4,353
│    └─SandwichFc: 2-2                   [1, 64]                   8,321
│    └─SandwichFc: 2-3                   [1, 64]                   8,321
│    └─SandwichFc: 2-4                   [1, 64]                   8,321
│    └─SandwichFc: 2-5                   [1, 64]                   8,321
│    └─SandwichFc: 2-6                   [1, 64]                   8,321
│    └─SandwichFc: 2-7                   [1, 64]                   8,321
│    └─SandwichLin: 2-8                  [1, 2]                    135
├─Sequential: 1-2                        [1, 2]                    (recursive)
│    └─SandwichFc: 2-9                   [1, 64]                   (recursive)
│    └─SandwichFc: 2-10                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-11                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-12                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-13                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-14                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-15                  [1, 64]                   (recursive)
│    └─SandwichLin: 2-16                 [1, 2]                    (recursive)
==========================================================================================
Total params: 54,420
Trainable params: 54,414
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.11
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.22
Estimated Total Size (MB): 0.22
==========================================================================================
==> Saving initial model weights...
==> Start training...
==> Number of param_groups in optimizer: 1
Epoch: 001 | Train Loss: 8.6034701 | Grad norm: 21.870604 | Time: 7s265ms
Epoch: 001 | Test Loss: 8.5632293 | Time: 922ms
==> Save the model at epoch 001 with test loss 8.5632293
Epoch: 002 | Train Loss: 0.6690687 | Grad norm: 4.624646 | Time: 6s906ms
Epoch: 002 | Test Loss: 0.0030347 | Time: 979ms
==> Save the model at epoch 002 with test loss 0.0030347
Epoch: 003 | Train Loss: 0.0044799 | Grad norm: 2.214293 | Time: 7s86ms
Epoch: 003 | Test Loss: 0.0048751 | Time: 921ms
Epoch: 004 | Train Loss: 0.0069320 | Grad norm: 2.817200 | Time: 6s901ms
Epoch: 004 | Test Loss: 0.0052970 | Time: 1s23ms
Epoch: 005 | Train Loss: 0.0094947 | Grad norm: 3.523793 | Time: 6s884ms
Epoch: 005 | Test Loss: 0.0030541 | Time: 919ms
Epoch: 006 | Train Loss: 0.0118954 | Grad norm: 3.652239 | Time: 6s976ms
Epoch: 006 | Test Loss: 0.0124131 | Time: 919ms
Epoch: 007 | Train Loss: 0.0143925 | Grad norm: 4.065432 | Time: 6s916ms
Epoch: 007 | Test Loss: 0.0104470 | Time: 921ms
Epoch: 008 | Train Loss: 0.0174496 | Grad norm: 4.070409 | Time: 6s783ms
Epoch: 008 | Test Loss: 0.0119612 | Time: 917ms
Epoch: 009 | Train Loss: 0.0194920 | Grad norm: 4.295553 | Time: 6s819ms
Epoch: 009 | Test Loss: 0.0094277 | Time: 1s205ms
Epoch: 010 | Train Loss: 0.0193006 | Grad norm: 3.888960 | Time: 7s168ms
Epoch: 010 | Test Loss: 0.0129785 | Time: 913ms
Epoch: 011 | Train Loss: 0.0137012 | Grad norm: 3.582303 | Time: 7s53ms
Epoch: 011 | Test Loss: 0.0089139 | Time: 910ms
Epoch: 012 | Train Loss: 0.0119750 | Grad norm: 3.187131 | Time: 7s112ms
Epoch: 012 | Test Loss: 0.0119574 | Time: 907ms
Epoch: 013 | Train Loss: 0.0124175 | Grad norm: 2.703128 | Time: 6s802ms
Epoch: 013 | Test Loss: 0.0083119 | Time: 930ms
Epoch: 014 | Train Loss: 0.0092092 | Grad norm: 2.812800 | Time: 7s313ms
Epoch: 014 | Test Loss: 0.0085466 | Time: 991ms
Epoch: 015 | Train Loss: 0.0082585 | Grad norm: 2.565852 | Time: 7s101ms
Epoch: 015 | Test Loss: 0.0090501 | Time: 912ms
Epoch: 016 | Train Loss: 0.0077779 | Grad norm: 2.337288 | Time: 6s910ms
Epoch: 016 | Test Loss: 0.0054514 | Time: 990ms
Epoch: 017 | Train Loss: 0.0056086 | Grad norm: 1.876163 | Time: 6s891ms
Epoch: 017 | Test Loss: 0.0043658 | Time: 915ms
Epoch: 018 | Train Loss: 0.0065249 | Grad norm: 1.883858 | Time: 7s134ms
Epoch: 018 | Test Loss: 0.0058510 | Time: 921ms
Epoch: 019 | Train Loss: 0.0053205 | Grad norm: 1.931086 | Time: 6s952ms
Epoch: 019 | Test Loss: 0.0054178 | Time: 918ms
Epoch: 020 | Train Loss: 0.0044078 | Grad norm: 1.753768 | Time: 7s313ms
Epoch: 020 | Test Loss: 0.0034761 | Time: 914ms
Epoch: 021 | Train Loss: 0.0042324 | Grad norm: 1.616437 | Time: 7s217ms
Epoch: 021 | Test Loss: 0.0036491 | Time: 985ms
Epoch: 022 | Train Loss: 0.0031545 | Grad norm: 1.151412 | Time: 6s948ms
Epoch: 022 | Test Loss: 0.0010553 | Time: 922ms
==> Save the model at epoch 022 with test loss 0.0010553
Epoch: 023 | Train Loss: 0.0009882 | Grad norm: 0.384973 | Time: 7s172ms
Epoch: 023 | Test Loss: 0.0012007 | Time: 923ms
Epoch: 024 | Train Loss: 0.0009755 | Grad norm: 0.395365 | Time: 7s217ms
Epoch: 024 | Test Loss: 0.0007763 | Time: 914ms
==> Save the model at epoch 024 with test loss 0.0007763
Epoch: 025 | Train Loss: 0.0010573 | Grad norm: 0.486830 | Time: 7s27ms
Epoch: 025 | Test Loss: 0.0011052 | Time: 916ms
Epoch: 026 | Train Loss: 0.0008793 | Grad norm: 0.363762 | Time: 7s304ms
Epoch: 026 | Test Loss: 0.0008681 | Time: 916ms
Epoch: 027 | Train Loss: 0.0007917 | Grad norm: 0.298356 | Time: 7s129ms
Epoch: 027 | Test Loss: 0.0007432 | Time: 1s43ms
==> Save the model at epoch 027 with test loss 0.0007432
Epoch: 028 | Train Loss: 0.0007681 | Grad norm: 0.302310 | Time: 7s245ms
Epoch: 028 | Test Loss: 0.0007115 | Time: 988ms
==> Save the model at epoch 028 with test loss 0.0007115
Epoch: 029 | Train Loss: 0.0007326 | Grad norm: 0.255750 | Time: 6s967ms
Epoch: 029 | Test Loss: 0.0007079 | Time: 916ms
==> Save the model at epoch 029 with test loss 0.0007079
Epoch: 030 | Train Loss: 0.0006940 | Grad norm: 0.241569 | Time: 6s757ms
Epoch: 030 | Test Loss: 0.0006118 | Time: 918ms
==> Save the model at epoch 030 with test loss 0.0006118
Epoch: 031 | Train Loss: 0.0006412 | Grad norm: 0.190077 | Time: 7s261ms
Epoch: 031 | Test Loss: 0.0006879 | Time: 913ms
Epoch: 032 | Train Loss: 0.0006386 | Grad norm: 0.181534 | Time: 6s904ms
Epoch: 032 | Test Loss: 0.0006517 | Time: 917ms
Epoch: 033 | Train Loss: 0.0006170 | Grad norm: 0.166906 | Time: 7s135ms
Epoch: 033 | Test Loss: 0.0006501 | Time: 925ms
Epoch: 034 | Train Loss: 0.0006090 | Grad norm: 0.153104 | Time: 7s92ms
Epoch: 034 | Test Loss: 0.0006121 | Time: 913ms
Epoch: 035 | Train Loss: 0.0005786 | Grad norm: 0.115409 | Time: 6s910ms
Epoch: 035 | Test Loss: 0.0005835 | Time: 979ms
==> Save the model at epoch 035 with test loss 0.0005835
Epoch: 036 | Train Loss: 0.0005718 | Grad norm: 0.116579 | Time: 7s54ms
Epoch: 036 | Test Loss: 0.0006053 | Time: 920ms
Epoch: 037 | Train Loss: 0.0005675 | Grad norm: 0.115723 | Time: 7s12ms
Epoch: 037 | Test Loss: 0.0005738 | Time: 925ms
==> Save the model at epoch 037 with test loss 0.0005738
Epoch: 038 | Train Loss: 0.0005527 | Grad norm: 0.084539 | Time: 7s95ms
Epoch: 038 | Test Loss: 0.0005687 | Time: 918ms
==> Save the model at epoch 038 with test loss 0.0005687
Epoch: 039 | Train Loss: 0.0005473 | Grad norm: 0.076370 | Time: 7s257ms
Epoch: 039 | Test Loss: 0.0005591 | Time: 915ms
==> Save the model at epoch 039 with test loss 0.0005591
Epoch: 040 | Train Loss: 0.0005428 | Grad norm: 0.066113 | Time: 7s171ms
Epoch: 040 | Test Loss: 0.0005555 | Time: 1s72ms
==> Save the model at epoch 040 with test loss 0.0005555
Total time: 5m20s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[0.48014596 0.48395684]
==> Output transform to be applied to the neural network (trained):
[2.0663 2.0805]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Process finished.
