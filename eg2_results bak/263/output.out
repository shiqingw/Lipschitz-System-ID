==> torch device:  cuda:2
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 1.00
==> Further split seed:  None
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[1. 1.]
==> Ouput transform to be applied to the neural network:
[1. 1.]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─Linear: 2-1                       [1, 64]                   192
│    └─LeakyReLU: 2-2                    [1, 64]                   --
│    └─Linear: 2-3                       [1, 64]                   4,160
│    └─LeakyReLU: 2-4                    [1, 64]                   --
│    └─Linear: 2-5                       [1, 64]                   4,160
│    └─LeakyReLU: 2-6                    [1, 64]                   --
│    └─Linear: 2-7                       [1, 64]                   4,160
│    └─LeakyReLU: 2-8                    [1, 64]                   --
│    └─Linear: 2-9                       [1, 64]                   4,160
│    └─LeakyReLU: 2-10                   [1, 64]                   --
│    └─Linear: 2-11                      [1, 64]                   4,160
│    └─LeakyReLU: 2-12                   [1, 64]                   --
│    └─Linear: 2-13                      [1, 64]                   4,160
│    └─LeakyReLU: 2-14                   [1, 64]                   --
│    └─Linear: 2-15                      [1, 2]                    130
==========================================================================================
Total params: 25,288
Trainable params: 25,282
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.03
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.10
Estimated Total Size (MB): 0.10
==========================================================================================
==> Saving initial model weights...
==> Start training...
Epoch: 001 | Loss: 0.5173008 | L2 loss: 0.4084224 | Lip loss: 0.1088785 | Grad norm: 2.354173 | Time: 58s169ms
Epoch: 001 | Test Loss: 0.0146237 | Time: 851ms
==> Save the model at epoch 001 with test loss 0.0146237
Epoch: 002 | Loss: 0.1226883 | L2 loss: 0.0107969 | Lip loss: 0.1118914 | Grad norm: 1.224865 | Time: 55s914ms
Epoch: 002 | Test Loss: 0.0108889 | Time: 726ms
==> Save the model at epoch 002 with test loss 0.0108889
Epoch: 003 | Loss: 0.1217751 | L2 loss: 0.0094012 | Lip loss: 0.1123739 | Grad norm: 1.054260 | Time: 55s426ms
Epoch: 003 | Test Loss: 0.0107384 | Time: 730ms
==> Save the model at epoch 003 with test loss 0.0107384
Epoch: 004 | Loss: 0.1211860 | L2 loss: 0.0092145 | Lip loss: 0.1119715 | Grad norm: 1.012392 | Time: 56s155ms
Epoch: 004 | Test Loss: 0.0093065 | Time: 721ms
==> Save the model at epoch 004 with test loss 0.0093065
Epoch: 005 | Loss: 0.1206715 | L2 loss: 0.0085313 | Lip loss: 0.1121401 | Grad norm: 0.965438 | Time: 56s295ms
Epoch: 005 | Test Loss: 0.0076603 | Time: 725ms
==> Save the model at epoch 005 with test loss 0.0076603
Epoch: 006 | Loss: 0.1156697 | L2 loss: 0.0040990 | Lip loss: 0.1115707 | Grad norm: 0.478366 | Time: 57s81ms
Epoch: 006 | Test Loss: 0.0051956 | Time: 730ms
==> Save the model at epoch 006 with test loss 0.0051956
Epoch: 007 | Loss: 0.1154783 | L2 loss: 0.0040993 | Lip loss: 0.1113790 | Grad norm: 0.483563 | Time: 56s364ms
Epoch: 007 | Test Loss: 0.0046109 | Time: 719ms
==> Save the model at epoch 007 with test loss 0.0046109
Epoch: 008 | Loss: 0.1157171 | L2 loss: 0.0042671 | Lip loss: 0.1114501 | Grad norm: 0.488288 | Time: 57s72ms
Epoch: 008 | Test Loss: 0.0036299 | Time: 803ms
==> Save the model at epoch 008 with test loss 0.0036299
Epoch: 009 | Loss: 0.1154787 | L2 loss: 0.0041762 | Lip loss: 0.1113026 | Grad norm: 0.496935 | Time: 56s95ms
Epoch: 009 | Test Loss: 0.0042197 | Time: 717ms
Epoch: 010 | Loss: 0.1152384 | L2 loss: 0.0040559 | Lip loss: 0.1111825 | Grad norm: 0.485938 | Time: 56s680ms
Epoch: 010 | Test Loss: 0.0047699 | Time: 731ms
Epoch: 011 | Loss: 0.1151404 | L2 loss: 0.0037142 | Lip loss: 0.1114262 | Grad norm: 0.424184 | Time: 57s427ms
Epoch: 011 | Test Loss: 0.0037767 | Time: 728ms
Epoch: 012 | Loss: 0.1147083 | L2 loss: 0.0036501 | Lip loss: 0.1110582 | Grad norm: 0.415577 | Time: 56s731ms
Epoch: 012 | Test Loss: 0.0037006 | Time: 728ms
Epoch: 013 | Loss: 0.1144999 | L2 loss: 0.0035838 | Lip loss: 0.1109161 | Grad norm: 0.409882 | Time: 56s594ms
Epoch: 013 | Test Loss: 0.0037276 | Time: 725ms
Epoch: 014 | Loss: 0.1147775 | L2 loss: 0.0036179 | Lip loss: 0.1111596 | Grad norm: 0.416412 | Time: 55s997ms
Epoch: 014 | Test Loss: 0.0036494 | Time: 750ms
Epoch: 015 | Loss: 0.1146222 | L2 loss: 0.0036072 | Lip loss: 0.1110150 | Grad norm: 0.417296 | Time: 55s722ms
Epoch: 015 | Test Loss: 0.0036972 | Time: 804ms
Epoch: 016 | Loss: 0.1146651 | L2 loss: 0.0036014 | Lip loss: 0.1110638 | Grad norm: 0.409609 | Time: 56s559ms
Epoch: 016 | Test Loss: 0.0036510 | Time: 737ms
Epoch: 017 | Loss: 0.1145203 | L2 loss: 0.0035720 | Lip loss: 0.1109483 | Grad norm: 0.406019 | Time: 56s452ms
Epoch: 017 | Test Loss: 0.0036456 | Time: 727ms
Epoch: 018 | Loss: 0.1148348 | L2 loss: 0.0035856 | Lip loss: 0.1112492 | Grad norm: 0.405206 | Time: 56s828ms
Epoch: 018 | Test Loss: 0.0036221 | Time: 749ms
==> Save the model at epoch 018 with test loss 0.0036221
Epoch: 019 | Loss: 0.1142631 | L2 loss: 0.0035414 | Lip loss: 0.1107217 | Grad norm: 0.405471 | Time: 57s101ms
Epoch: 019 | Test Loss: 0.0036087 | Time: 716ms
==> Save the model at epoch 019 with test loss 0.0036087
Epoch: 020 | Loss: 0.1149573 | L2 loss: 0.0035487 | Lip loss: 0.1114086 | Grad norm: 0.411697 | Time: 57s116ms
Epoch: 020 | Test Loss: 0.0035938 | Time: 736ms
==> Save the model at epoch 020 with test loss 0.0035938
Epoch: 021 | Loss: 0.1147178 | L2 loss: 0.0035328 | Lip loss: 0.1111850 | Grad norm: 0.397890 | Time: 56s603ms
Epoch: 021 | Test Loss: 0.0036064 | Time: 734ms
Epoch: 022 | Loss: 0.1144867 | L2 loss: 0.0035411 | Lip loss: 0.1109456 | Grad norm: 0.400831 | Time: 57s52ms
Epoch: 022 | Test Loss: 0.0036100 | Time: 725ms
Epoch: 023 | Loss: 0.1148074 | L2 loss: 0.0035419 | Lip loss: 0.1112655 | Grad norm: 0.408865 | Time: 57s170ms
Epoch: 023 | Test Loss: 0.0036126 | Time: 794ms
Epoch: 024 | Loss: 0.1144670 | L2 loss: 0.0035447 | Lip loss: 0.1109224 | Grad norm: 0.407690 | Time: 57s24ms
Epoch: 024 | Test Loss: 0.0036038 | Time: 722ms
Epoch: 025 | Loss: 0.1142306 | L2 loss: 0.0035327 | Lip loss: 0.1106979 | Grad norm: 0.402895 | Time: 56s806ms
Epoch: 025 | Test Loss: 0.0036011 | Time: 733ms
Epoch: 026 | Loss: 0.1151318 | L2 loss: 0.0035322 | Lip loss: 0.1115996 | Grad norm: 0.411638 | Time: 57s338ms
Epoch: 026 | Test Loss: 0.0036024 | Time: 733ms
Epoch: 027 | Loss: 0.1143056 | L2 loss: 0.0035329 | Lip loss: 0.1107727 | Grad norm: 0.411988 | Time: 57s679ms
Epoch: 027 | Test Loss: 0.0036032 | Time: 728ms
Epoch: 028 | Loss: 0.1145646 | L2 loss: 0.0035337 | Lip loss: 0.1110309 | Grad norm: 0.404649 | Time: 55s722ms
Epoch: 028 | Test Loss: 0.0036036 | Time: 721ms
Epoch: 029 | Loss: 0.1147878 | L2 loss: 0.0035343 | Lip loss: 0.1112535 | Grad norm: 0.407537 | Time: 57s78ms
Epoch: 029 | Test Loss: 0.0036047 | Time: 719ms
Epoch: 030 | Loss: 0.1148155 | L2 loss: 0.0035352 | Lip loss: 0.1112803 | Grad norm: 0.409154 | Time: 55s672ms
Epoch: 030 | Test Loss: 0.0036055 | Time: 793ms
Epoch: 031 | Loss: 0.1144879 | L2 loss: 0.0035358 | Lip loss: 0.1109521 | Grad norm: 0.408987 | Time: 55s358ms
Epoch: 031 | Test Loss: 0.0036055 | Time: 732ms
Epoch: 032 | Loss: 0.1148933 | L2 loss: 0.0035358 | Lip loss: 0.1113574 | Grad norm: 0.408525 | Time: 55s193ms
Epoch: 032 | Test Loss: 0.0036055 | Time: 723ms
Epoch: 033 | Loss: 0.1144514 | L2 loss: 0.0035358 | Lip loss: 0.1109156 | Grad norm: 0.403585 | Time: 57s350ms
Epoch: 033 | Test Loss: 0.0036055 | Time: 731ms
Epoch: 034 | Loss: 0.1148887 | L2 loss: 0.0035358 | Lip loss: 0.1113529 | Grad norm: 0.403878 | Time: 56s850ms
Epoch: 034 | Test Loss: 0.0036056 | Time: 730ms
Epoch: 035 | Loss: 0.1146724 | L2 loss: 0.0035359 | Lip loss: 0.1111366 | Grad norm: 0.399354 | Time: 55s776ms
Epoch: 035 | Test Loss: 0.0036056 | Time: 718ms
Epoch: 036 | Loss: 0.1148513 | L2 loss: 0.0035359 | Lip loss: 0.1113154 | Grad norm: 0.404373 | Time: 56s601ms
Epoch: 036 | Test Loss: 0.0036056 | Time: 717ms
Epoch: 037 | Loss: 0.1148070 | L2 loss: 0.0035359 | Lip loss: 0.1112711 | Grad norm: 0.402744 | Time: 56s44ms
Epoch: 037 | Test Loss: 0.0036056 | Time: 803ms
Epoch: 038 | Loss: 0.1146507 | L2 loss: 0.0035359 | Lip loss: 0.1111148 | Grad norm: 0.409656 | Time: 55s602ms
Epoch: 038 | Test Loss: 0.0036056 | Time: 712ms
Epoch: 039 | Loss: 0.1144529 | L2 loss: 0.0035359 | Lip loss: 0.1109171 | Grad norm: 0.407185 | Time: 56s138ms
Epoch: 039 | Test Loss: 0.0036056 | Time: 711ms
Epoch: 040 | Loss: 0.1147499 | L2 loss: 0.0035359 | Lip loss: 0.1112140 | Grad norm: 0.400544 | Time: 56s386ms
Epoch: 040 | Test Loss: 0.0036056 | Time: 720ms
Total time: 38m10s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[1. 1.]
==> Output transform to be applied to the neural network (trained):
[1. 1.]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Drawing l2 loss...
==> Drawing lip loss...
==> Process finished.
