==> torch device:  cuda:3
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 1.00
==> Further split seed:  None
==> Lipschitz constant: 4.00
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[0.5576312  0.56041247]
==> Ouput transform to be applied to the neural network:
[1.7847 1.7916]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─SandwichFc: 2-1                   [1, 64]                   4,353
│    └─SandwichFc: 2-2                   [1, 64]                   8,321
│    └─SandwichFc: 2-3                   [1, 64]                   8,321
│    └─SandwichFc: 2-4                   [1, 64]                   8,321
│    └─SandwichFc: 2-5                   [1, 64]                   8,321
│    └─SandwichFc: 2-6                   [1, 64]                   8,321
│    └─SandwichFc: 2-7                   [1, 64]                   8,321
│    └─SandwichLin: 2-8                  [1, 2]                    135
├─Sequential: 1-2                        [1, 2]                    (recursive)
│    └─SandwichFc: 2-9                   [1, 64]                   (recursive)
│    └─SandwichFc: 2-10                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-11                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-12                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-13                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-14                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-15                  [1, 64]                   (recursive)
│    └─SandwichLin: 2-16                 [1, 2]                    (recursive)
==========================================================================================
Total params: 54,420
Trainable params: 54,414
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.11
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.22
Estimated Total Size (MB): 0.22
==========================================================================================
==> Saving initial model weights...
==> Start training...
==> Number of param_groups in optimizer: 1
Epoch: 001 | Train Loss: 6.3901490 | Grad norm: 7.764445 | Time: 27s751ms
Epoch: 001 | Test Loss: 6.3740991 | Time: 916ms
==> Save the model at epoch 001 with test loss 6.3740991
Epoch: 002 | Train Loss: 0.1753956 | Grad norm: 1.135963 | Time: 28s302ms
Epoch: 002 | Test Loss: 0.0031293 | Time: 912ms
==> Save the model at epoch 002 with test loss 0.0031293
Epoch: 003 | Train Loss: 0.0046694 | Grad norm: 1.094103 | Time: 27s468ms
Epoch: 003 | Test Loss: 0.0045730 | Time: 911ms
Epoch: 004 | Train Loss: 0.0065677 | Grad norm: 1.578770 | Time: 27s642ms
Epoch: 004 | Test Loss: 0.0089364 | Time: 914ms
Epoch: 005 | Train Loss: 0.0111509 | Grad norm: 2.346034 | Time: 26s932ms
Epoch: 005 | Test Loss: 0.0091676 | Time: 914ms
Epoch: 006 | Train Loss: 0.0078847 | Grad norm: 1.670371 | Time: 27s395ms
Epoch: 006 | Test Loss: 0.0032877 | Time: 916ms
Epoch: 007 | Train Loss: 0.0075383 | Grad norm: 1.675506 | Time: 27s22ms
Epoch: 007 | Test Loss: 0.0087059 | Time: 926ms
Epoch: 008 | Train Loss: 0.0075102 | Grad norm: 1.579532 | Time: 26s983ms
Epoch: 008 | Test Loss: 0.0037850 | Time: 916ms
Epoch: 009 | Train Loss: 0.0079773 | Grad norm: 1.560541 | Time: 27s835ms
Epoch: 009 | Test Loss: 0.0064180 | Time: 913ms
Epoch: 010 | Train Loss: 0.0058536 | Grad norm: 1.067752 | Time: 27s401ms
Epoch: 010 | Test Loss: 0.0039421 | Time: 1s136ms
Epoch: 011 | Train Loss: 0.0104161 | Grad norm: 1.770784 | Time: 28s166ms
Epoch: 011 | Test Loss: 0.0161521 | Time: 917ms
Epoch: 012 | Train Loss: 0.0082094 | Grad norm: 1.381923 | Time: 27s763ms
Epoch: 012 | Test Loss: 0.0031104 | Time: 992ms
==> Save the model at epoch 012 with test loss 0.0031104
Epoch: 013 | Train Loss: 0.0033862 | Grad norm: 0.380573 | Time: 28s218ms
Epoch: 013 | Test Loss: 0.0030135 | Time: 983ms
==> Save the model at epoch 013 with test loss 0.0030135
Epoch: 014 | Train Loss: 0.0037953 | Grad norm: 0.487835 | Time: 27s703ms
Epoch: 014 | Test Loss: 0.0123135 | Time: 986ms
Epoch: 015 | Train Loss: 0.0089372 | Grad norm: 1.435798 | Time: 27s879ms
Epoch: 015 | Test Loss: 0.0030890 | Time: 918ms
Epoch: 016 | Train Loss: 0.0032722 | Grad norm: 0.340767 | Time: 28s100ms
Epoch: 016 | Test Loss: 0.0030671 | Time: 913ms
Epoch: 017 | Train Loss: 0.0034001 | Grad norm: 0.386295 | Time: 27s461ms
Epoch: 017 | Test Loss: 0.0030420 | Time: 919ms
Epoch: 018 | Train Loss: 0.0034025 | Grad norm: 0.380950 | Time: 27s745ms
Epoch: 018 | Test Loss: 0.0030393 | Time: 923ms
Epoch: 019 | Train Loss: 0.0032942 | Grad norm: 0.350784 | Time: 27s599ms
Epoch: 019 | Test Loss: 0.0028088 | Time: 921ms
==> Save the model at epoch 019 with test loss 0.0028088
Epoch: 020 | Train Loss: 0.0032913 | Grad norm: 0.376334 | Time: 27s433ms
Epoch: 020 | Test Loss: 0.0030473 | Time: 920ms
Epoch: 021 | Train Loss: 0.0032432 | Grad norm: 0.345622 | Time: 27s924ms
Epoch: 021 | Test Loss: 0.0031539 | Time: 913ms
Epoch: 022 | Train Loss: 0.0032194 | Grad norm: 0.336268 | Time: 27s99ms
Epoch: 022 | Test Loss: 0.0031043 | Time: 914ms
Epoch: 023 | Train Loss: 0.0031047 | Grad norm: 0.290272 | Time: 28s91ms
Epoch: 023 | Test Loss: 0.0032861 | Time: 928ms
Epoch: 024 | Train Loss: 0.0031160 | Grad norm: 0.295058 | Time: 27s511ms
Epoch: 024 | Test Loss: 0.0031918 | Time: 926ms
Epoch: 025 | Train Loss: 0.0030394 | Grad norm: 0.273788 | Time: 27s944ms
Epoch: 025 | Test Loss: 0.0028411 | Time: 915ms
Epoch: 026 | Train Loss: 0.0029802 | Grad norm: 0.246241 | Time: 28s677ms
Epoch: 026 | Test Loss: 0.0028547 | Time: 916ms
Epoch: 027 | Train Loss: 0.0029547 | Grad norm: 0.234455 | Time: 27s940ms
Epoch: 027 | Test Loss: 0.0028188 | Time: 983ms
Epoch: 028 | Train Loss: 0.0029181 | Grad norm: 0.220152 | Time: 27s862ms
Epoch: 028 | Test Loss: 0.0030255 | Time: 983ms
Epoch: 029 | Train Loss: 0.0028771 | Grad norm: 0.202481 | Time: 27s588ms
Epoch: 029 | Test Loss: 0.0028495 | Time: 983ms
Epoch: 030 | Train Loss: 0.0028811 | Grad norm: 0.219144 | Time: 27s854ms
Epoch: 030 | Test Loss: 0.0028320 | Time: 922ms
Epoch: 031 | Train Loss: 0.0028246 | Grad norm: 0.187870 | Time: 27s696ms
Epoch: 031 | Test Loss: 0.0029181 | Time: 918ms
Epoch: 032 | Train Loss: 0.0028006 | Grad norm: 0.174954 | Time: 27s876ms
Epoch: 032 | Test Loss: 0.0028055 | Time: 922ms
==> Save the model at epoch 032 with test loss 0.0028055
Epoch: 033 | Train Loss: 0.0027849 | Grad norm: 0.169612 | Time: 28s245ms
Epoch: 033 | Test Loss: 0.0027760 | Time: 915ms
==> Save the model at epoch 033 with test loss 0.0027760
Epoch: 034 | Train Loss: 0.0027557 | Grad norm: 0.148311 | Time: 27s951ms
Epoch: 034 | Test Loss: 0.0027858 | Time: 923ms
Epoch: 035 | Train Loss: 0.0027317 | Grad norm: 0.139522 | Time: 28s54ms
Epoch: 035 | Test Loss: 0.0026932 | Time: 934ms
==> Save the model at epoch 035 with test loss 0.0026932
Epoch: 036 | Train Loss: 0.0027149 | Grad norm: 0.126617 | Time: 27s714ms
Epoch: 036 | Test Loss: 0.0026886 | Time: 917ms
==> Save the model at epoch 036 with test loss 0.0026886
Epoch: 037 | Train Loss: 0.0026931 | Grad norm: 0.108405 | Time: 27s212ms
Epoch: 037 | Test Loss: 0.0027006 | Time: 917ms
Epoch: 038 | Train Loss: 0.0026769 | Grad norm: 0.097865 | Time: 27s402ms
Epoch: 038 | Test Loss: 0.0026881 | Time: 933ms
==> Save the model at epoch 038 with test loss 0.0026881
Epoch: 039 | Train Loss: 0.0026671 | Grad norm: 0.088672 | Time: 27s462ms
Epoch: 039 | Test Loss: 0.0026836 | Time: 918ms
==> Save the model at epoch 039 with test loss 0.0026836
Epoch: 040 | Train Loss: 0.0026585 | Grad norm: 0.079629 | Time: 27s345ms
Epoch: 040 | Test Loss: 0.0026656 | Time: 1s126ms
==> Save the model at epoch 040 with test loss 0.0026656
Total time: 19m5s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[0.5576312  0.56041247]
==> Output transform to be applied to the neural network (trained):
[1.7847 1.7916]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Process finished.
