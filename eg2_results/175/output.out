==> torch device:  cuda:2
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.25
==> Further split seed:  None
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[1. 1.]
==> Ouput transform to be applied to the neural network:
[1. 1.]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─Linear: 2-1                       [1, 64]                   192
│    └─LeakyReLU: 2-2                    [1, 64]                   --
│    └─Linear: 2-3                       [1, 64]                   4,160
│    └─LeakyReLU: 2-4                    [1, 64]                   --
│    └─Linear: 2-5                       [1, 64]                   4,160
│    └─LeakyReLU: 2-6                    [1, 64]                   --
│    └─Linear: 2-7                       [1, 64]                   4,160
│    └─LeakyReLU: 2-8                    [1, 64]                   --
│    └─Linear: 2-9                       [1, 64]                   4,160
│    └─LeakyReLU: 2-10                   [1, 64]                   --
│    └─Linear: 2-11                      [1, 64]                   4,160
│    └─LeakyReLU: 2-12                   [1, 64]                   --
│    └─Linear: 2-13                      [1, 64]                   4,160
│    └─LeakyReLU: 2-14                   [1, 64]                   --
│    └─Linear: 2-15                      [1, 2]                    130
==========================================================================================
Total params: 25,288
Trainable params: 25,282
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.03
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.10
Estimated Total Size (MB): 0.10
==========================================================================================
==> Saving initial model weights...
==> Start training...
Epoch: 001 | Loss: 1.1765826 | L2 loss: 1.1765825 | Lip loss: 0.0000001 | Grad norm: 3.043956 | Time: 14s801ms
Epoch: 001 | Test Loss: 0.0083695 | Time: 733ms
==> Save the model at epoch 001 with test loss 0.0083695
Epoch: 002 | Loss: 0.0088944 | L2 loss: 0.0088943 | Lip loss: 0.0000001 | Grad norm: 1.472135 | Time: 14s248ms
Epoch: 002 | Test Loss: 0.0066538 | Time: 723ms
==> Save the model at epoch 002 with test loss 0.0066538
Epoch: 003 | Loss: 0.0067126 | L2 loss: 0.0067125 | Lip loss: 0.0000001 | Grad norm: 0.995727 | Time: 13s937ms
Epoch: 003 | Test Loss: 0.0050223 | Time: 806ms
==> Save the model at epoch 003 with test loss 0.0050223
Epoch: 004 | Loss: 0.0058790 | L2 loss: 0.0058789 | Lip loss: 0.0000001 | Grad norm: 0.904593 | Time: 14s211ms
Epoch: 004 | Test Loss: 0.0037427 | Time: 728ms
==> Save the model at epoch 004 with test loss 0.0037427
Epoch: 005 | Loss: 0.0046804 | L2 loss: 0.0046803 | Lip loss: 0.0000001 | Grad norm: 0.677849 | Time: 14s291ms
Epoch: 005 | Test Loss: 0.0034814 | Time: 742ms
==> Save the model at epoch 005 with test loss 0.0034814
Epoch: 006 | Loss: 0.0031141 | L2 loss: 0.0031140 | Lip loss: 0.0000001 | Grad norm: 0.136333 | Time: 14s172ms
Epoch: 006 | Test Loss: 0.0031620 | Time: 724ms
==> Save the model at epoch 006 with test loss 0.0031620
Epoch: 007 | Loss: 0.0030979 | L2 loss: 0.0030977 | Lip loss: 0.0000001 | Grad norm: 0.152816 | Time: 14s317ms
Epoch: 007 | Test Loss: 0.0031663 | Time: 740ms
Epoch: 008 | Loss: 0.0030721 | L2 loss: 0.0030720 | Lip loss: 0.0000001 | Grad norm: 0.141153 | Time: 13s965ms
Epoch: 008 | Test Loss: 0.0031620 | Time: 734ms
Epoch: 009 | Loss: 0.0030875 | L2 loss: 0.0030874 | Lip loss: 0.0000001 | Grad norm: 0.184777 | Time: 13s963ms
Epoch: 009 | Test Loss: 0.0031028 | Time: 742ms
==> Save the model at epoch 009 with test loss 0.0031028
Epoch: 010 | Loss: 0.0030562 | L2 loss: 0.0030561 | Lip loss: 0.0000001 | Grad norm: 0.158061 | Time: 14s77ms
Epoch: 010 | Test Loss: 0.0031160 | Time: 798ms
Epoch: 011 | Loss: 0.0029936 | L2 loss: 0.0029935 | Lip loss: 0.0000001 | Grad norm: 0.111036 | Time: 13s800ms
Epoch: 011 | Test Loss: 0.0030842 | Time: 731ms
==> Save the model at epoch 011 with test loss 0.0030842
Epoch: 012 | Loss: 0.0029977 | L2 loss: 0.0029976 | Lip loss: 0.0000001 | Grad norm: 0.108192 | Time: 14s222ms
Epoch: 012 | Test Loss: 0.0030776 | Time: 728ms
==> Save the model at epoch 012 with test loss 0.0030776
Epoch: 013 | Loss: 0.0029924 | L2 loss: 0.0029923 | Lip loss: 0.0000001 | Grad norm: 0.105631 | Time: 14s429ms
Epoch: 013 | Test Loss: 0.0030708 | Time: 734ms
==> Save the model at epoch 013 with test loss 0.0030708
Epoch: 014 | Loss: 0.0029877 | L2 loss: 0.0029876 | Lip loss: 0.0000001 | Grad norm: 0.107127 | Time: 14s255ms
Epoch: 014 | Test Loss: 0.0030746 | Time: 734ms
Epoch: 015 | Loss: 0.0029885 | L2 loss: 0.0029884 | Lip loss: 0.0000001 | Grad norm: 0.113010 | Time: 13s868ms
Epoch: 015 | Test Loss: 0.0030663 | Time: 962ms
==> Save the model at epoch 015 with test loss 0.0030663
Epoch: 016 | Loss: 0.0029804 | L2 loss: 0.0029803 | Lip loss: 0.0000001 | Grad norm: 0.100383 | Time: 13s670ms
Epoch: 016 | Test Loss: 0.0030635 | Time: 738ms
==> Save the model at epoch 016 with test loss 0.0030635
Epoch: 017 | Loss: 0.0029796 | L2 loss: 0.0029795 | Lip loss: 0.0000001 | Grad norm: 0.099517 | Time: 14s622ms
Epoch: 017 | Test Loss: 0.0030630 | Time: 738ms
==> Save the model at epoch 017 with test loss 0.0030630
Epoch: 018 | Loss: 0.0029828 | L2 loss: 0.0029827 | Lip loss: 0.0000001 | Grad norm: 0.098551 | Time: 14s485ms
Epoch: 018 | Test Loss: 0.0030620 | Time: 738ms
==> Save the model at epoch 018 with test loss 0.0030620
Epoch: 019 | Loss: 0.0029778 | L2 loss: 0.0029777 | Lip loss: 0.0000001 | Grad norm: 0.100403 | Time: 14s93ms
Epoch: 019 | Test Loss: 0.0030624 | Time: 743ms
Epoch: 020 | Loss: 0.0029753 | L2 loss: 0.0029752 | Lip loss: 0.0000001 | Grad norm: 0.098532 | Time: 14s275ms
Epoch: 020 | Test Loss: 0.0030619 | Time: 767ms
==> Save the model at epoch 020 with test loss 0.0030619
Epoch: 021 | Loss: 0.0029760 | L2 loss: 0.0029759 | Lip loss: 0.0000001 | Grad norm: 0.100317 | Time: 13s929ms
Epoch: 021 | Test Loss: 0.0030614 | Time: 729ms
==> Save the model at epoch 021 with test loss 0.0030614
Epoch: 022 | Loss: 0.0029776 | L2 loss: 0.0029775 | Lip loss: 0.0000001 | Grad norm: 0.094014 | Time: 14s123ms
Epoch: 022 | Test Loss: 0.0030611 | Time: 797ms
==> Save the model at epoch 022 with test loss 0.0030611
Epoch: 023 | Loss: 0.0029773 | L2 loss: 0.0029772 | Lip loss: 0.0000001 | Grad norm: 0.092964 | Time: 14s99ms
Epoch: 023 | Test Loss: 0.0030611 | Time: 722ms
Epoch: 024 | Loss: 0.0029771 | L2 loss: 0.0029770 | Lip loss: 0.0000001 | Grad norm: 0.098375 | Time: 14s56ms
Epoch: 024 | Test Loss: 0.0030611 | Time: 735ms
==> Save the model at epoch 024 with test loss 0.0030611
Epoch: 025 | Loss: 0.0029743 | L2 loss: 0.0029742 | Lip loss: 0.0000001 | Grad norm: 0.096145 | Time: 14s391ms
Epoch: 025 | Test Loss: 0.0030610 | Time: 729ms
==> Save the model at epoch 025 with test loss 0.0030610
Epoch: 026 | Loss: 0.0029762 | L2 loss: 0.0029761 | Lip loss: 0.0000001 | Grad norm: 0.092300 | Time: 14s323ms
Epoch: 026 | Test Loss: 0.0030610 | Time: 734ms
==> Save the model at epoch 026 with test loss 0.0030610
Epoch: 027 | Loss: 0.0029776 | L2 loss: 0.0029775 | Lip loss: 0.0000001 | Grad norm: 0.098717 | Time: 14s142ms
Epoch: 027 | Test Loss: 0.0030610 | Time: 790ms
==> Save the model at epoch 027 with test loss 0.0030610
Epoch: 028 | Loss: 0.0029744 | L2 loss: 0.0029743 | Lip loss: 0.0000001 | Grad norm: 0.095471 | Time: 14s226ms
Epoch: 028 | Test Loss: 0.0030610 | Time: 791ms
==> Save the model at epoch 028 with test loss 0.0030610
Epoch: 029 | Loss: 0.0029741 | L2 loss: 0.0029740 | Lip loss: 0.0000001 | Grad norm: 0.100420 | Time: 13s752ms
Epoch: 029 | Test Loss: 0.0030610 | Time: 721ms
==> Save the model at epoch 029 with test loss 0.0030610
Epoch: 030 | Loss: 0.0029736 | L2 loss: 0.0029735 | Lip loss: 0.0000001 | Grad norm: 0.093254 | Time: 13s971ms
Epoch: 030 | Test Loss: 0.0030610 | Time: 739ms
==> Save the model at epoch 030 with test loss 0.0030610
Epoch: 031 | Loss: 0.0029775 | L2 loss: 0.0029774 | Lip loss: 0.0000001 | Grad norm: 0.098169 | Time: 13s859ms
Epoch: 031 | Test Loss: 0.0030610 | Time: 730ms
==> Save the model at epoch 031 with test loss 0.0030610
Epoch: 032 | Loss: 0.0029771 | L2 loss: 0.0029770 | Lip loss: 0.0000001 | Grad norm: 0.097556 | Time: 13s952ms
Epoch: 032 | Test Loss: 0.0030610 | Time: 733ms
==> Save the model at epoch 032 with test loss 0.0030610
Epoch: 033 | Loss: 0.0029764 | L2 loss: 0.0029763 | Lip loss: 0.0000001 | Grad norm: 0.095405 | Time: 13s993ms
Epoch: 033 | Test Loss: 0.0030610 | Time: 758ms
Epoch: 034 | Loss: 0.0029744 | L2 loss: 0.0029743 | Lip loss: 0.0000001 | Grad norm: 0.096059 | Time: 14s209ms
Epoch: 034 | Test Loss: 0.0030610 | Time: 801ms
==> Save the model at epoch 034 with test loss 0.0030610
Epoch: 035 | Loss: 0.0029744 | L2 loss: 0.0029743 | Lip loss: 0.0000001 | Grad norm: 0.098244 | Time: 14s215ms
Epoch: 035 | Test Loss: 0.0030610 | Time: 768ms
Epoch: 036 | Loss: 0.0029766 | L2 loss: 0.0029765 | Lip loss: 0.0000001 | Grad norm: 0.097712 | Time: 14s124ms
Epoch: 036 | Test Loss: 0.0030610 | Time: 720ms
==> Save the model at epoch 036 with test loss 0.0030610
Epoch: 037 | Loss: 0.0029765 | L2 loss: 0.0029764 | Lip loss: 0.0000001 | Grad norm: 0.096497 | Time: 14s529ms
Epoch: 037 | Test Loss: 0.0030610 | Time: 748ms
Epoch: 038 | Loss: 0.0029760 | L2 loss: 0.0029759 | Lip loss: 0.0000001 | Grad norm: 0.100757 | Time: 13s797ms
Epoch: 038 | Test Loss: 0.0030610 | Time: 728ms
Epoch: 039 | Loss: 0.0029749 | L2 loss: 0.0029748 | Lip loss: 0.0000001 | Grad norm: 0.099242 | Time: 14s410ms
Epoch: 039 | Test Loss: 0.0030610 | Time: 818ms
Epoch: 040 | Loss: 0.0029740 | L2 loss: 0.0029739 | Lip loss: 0.0000001 | Grad norm: 0.100006 | Time: 14s572ms
Epoch: 040 | Test Loss: 0.0030610 | Time: 826ms
Total time: 9m56s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[1. 1.]
==> Output transform to be applied to the neural network (trained):
[1. 1.]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Drawing l2 loss...
==> Drawing lip loss...
==> Process finished.
