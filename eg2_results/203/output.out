==> torch device:  cuda:2
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.25
==> Further split seed:  None
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[1. 1.]
==> Ouput transform to be applied to the neural network:
[1. 1.]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─Linear: 2-1                       [1, 64]                   192
│    └─LeakyReLU: 2-2                    [1, 64]                   --
│    └─Linear: 2-3                       [1, 64]                   4,160
│    └─LeakyReLU: 2-4                    [1, 64]                   --
│    └─Linear: 2-5                       [1, 64]                   4,160
│    └─LeakyReLU: 2-6                    [1, 64]                   --
│    └─Linear: 2-7                       [1, 64]                   4,160
│    └─LeakyReLU: 2-8                    [1, 64]                   --
│    └─Linear: 2-9                       [1, 64]                   4,160
│    └─LeakyReLU: 2-10                   [1, 64]                   --
│    └─Linear: 2-11                      [1, 64]                   4,160
│    └─LeakyReLU: 2-12                   [1, 64]                   --
│    └─Linear: 2-13                      [1, 64]                   4,160
│    └─LeakyReLU: 2-14                   [1, 64]                   --
│    └─Linear: 2-15                      [1, 2]                    130
==========================================================================================
Total params: 25,288
Trainable params: 25,282
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.03
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.10
Estimated Total Size (MB): 0.10
==========================================================================================
==> Saving initial model weights...
==> Start training...
Epoch: 001 | Loss: 2.8938354 | L2 loss: 2.8938344 | Lip loss: 0.0000010 | Grad norm: 3.618223 | Time: 9s90ms
Epoch: 001 | Test Loss: 0.2224862 | Time: 448ms
==> Save the model at epoch 001 with test loss 0.2224862
Epoch: 002 | Loss: 0.1867571 | L2 loss: 0.1867556 | Lip loss: 0.0000014 | Grad norm: 3.699989 | Time: 8s634ms
Epoch: 002 | Test Loss: 0.1068534 | Time: 528ms
==> Save the model at epoch 002 with test loss 0.1068534
Epoch: 003 | Loss: 0.0897925 | L2 loss: 0.0897910 | Lip loss: 0.0000015 | Grad norm: 2.886608 | Time: 8s841ms
Epoch: 003 | Test Loss: 0.1064427 | Time: 453ms
==> Save the model at epoch 003 with test loss 0.1064427
Epoch: 004 | Loss: 0.0679944 | L2 loss: 0.0679929 | Lip loss: 0.0000015 | Grad norm: 4.862851 | Time: 8s765ms
Epoch: 004 | Test Loss: 0.0394384 | Time: 442ms
==> Save the model at epoch 004 with test loss 0.0394384
Epoch: 005 | Loss: 0.0363060 | L2 loss: 0.0363045 | Lip loss: 0.0000015 | Grad norm: 3.051186 | Time: 8s644ms
Epoch: 005 | Test Loss: 0.0221666 | Time: 439ms
==> Save the model at epoch 005 with test loss 0.0221666
Epoch: 006 | Loss: 0.0167573 | L2 loss: 0.0167558 | Lip loss: 0.0000015 | Grad norm: 0.826176 | Time: 8s900ms
Epoch: 006 | Test Loss: 0.0157506 | Time: 450ms
==> Save the model at epoch 006 with test loss 0.0157506
Epoch: 007 | Loss: 0.0148692 | L2 loss: 0.0148677 | Lip loss: 0.0000015 | Grad norm: 0.741652 | Time: 8s683ms
Epoch: 007 | Test Loss: 0.0140955 | Time: 454ms
==> Save the model at epoch 007 with test loss 0.0140955
Epoch: 008 | Loss: 0.0136353 | L2 loss: 0.0136338 | Lip loss: 0.0000015 | Grad norm: 0.790918 | Time: 8s461ms
Epoch: 008 | Test Loss: 0.0134573 | Time: 438ms
==> Save the model at epoch 008 with test loss 0.0134573
Epoch: 009 | Loss: 0.0128608 | L2 loss: 0.0128594 | Lip loss: 0.0000014 | Grad norm: 0.801360 | Time: 8s845ms
Epoch: 009 | Test Loss: 0.0141483 | Time: 452ms
Epoch: 010 | Loss: 0.0120914 | L2 loss: 0.0120899 | Lip loss: 0.0000015 | Grad norm: 0.709139 | Time: 8s628ms
Epoch: 010 | Test Loss: 0.0122246 | Time: 449ms
==> Save the model at epoch 010 with test loss 0.0122246
Epoch: 011 | Loss: 0.0111627 | L2 loss: 0.0111612 | Lip loss: 0.0000014 | Grad norm: 0.473322 | Time: 8s675ms
Epoch: 011 | Test Loss: 0.0118006 | Time: 453ms
==> Save the model at epoch 011 with test loss 0.0118006
Epoch: 012 | Loss: 0.0110540 | L2 loss: 0.0110526 | Lip loss: 0.0000015 | Grad norm: 0.478621 | Time: 8s821ms
Epoch: 012 | Test Loss: 0.0117998 | Time: 461ms
==> Save the model at epoch 012 with test loss 0.0117998
Epoch: 013 | Loss: 0.0109909 | L2 loss: 0.0109894 | Lip loss: 0.0000014 | Grad norm: 0.479966 | Time: 8s832ms
Epoch: 013 | Test Loss: 0.0117823 | Time: 530ms
==> Save the model at epoch 013 with test loss 0.0117823
Epoch: 014 | Loss: 0.0109370 | L2 loss: 0.0109355 | Lip loss: 0.0000015 | Grad norm: 0.494456 | Time: 8s626ms
Epoch: 014 | Test Loss: 0.0116589 | Time: 456ms
==> Save the model at epoch 014 with test loss 0.0116589
Epoch: 015 | Loss: 0.0108625 | L2 loss: 0.0108611 | Lip loss: 0.0000014 | Grad norm: 0.455630 | Time: 8s332ms
Epoch: 015 | Test Loss: 0.0116879 | Time: 451ms
Epoch: 016 | Loss: 0.0107825 | L2 loss: 0.0107811 | Lip loss: 0.0000015 | Grad norm: 0.465625 | Time: 8s313ms
Epoch: 016 | Test Loss: 0.0115848 | Time: 505ms
==> Save the model at epoch 016 with test loss 0.0115848
Epoch: 017 | Loss: 0.0107627 | L2 loss: 0.0107612 | Lip loss: 0.0000014 | Grad norm: 0.453738 | Time: 8s490ms
Epoch: 017 | Test Loss: 0.0115802 | Time: 445ms
==> Save the model at epoch 017 with test loss 0.0115802
Epoch: 018 | Loss: 0.0108935 | L2 loss: 0.0108920 | Lip loss: 0.0000015 | Grad norm: 0.445347 | Time: 8s314ms
Epoch: 018 | Test Loss: 0.0115733 | Time: 446ms
==> Save the model at epoch 018 with test loss 0.0115733
Epoch: 019 | Loss: 0.0108553 | L2 loss: 0.0108539 | Lip loss: 0.0000014 | Grad norm: 0.436635 | Time: 8s290ms
Epoch: 019 | Test Loss: 0.0115610 | Time: 453ms
==> Save the model at epoch 019 with test loss 0.0115610
Epoch: 020 | Loss: 0.0107358 | L2 loss: 0.0107344 | Lip loss: 0.0000014 | Grad norm: 0.446213 | Time: 8s209ms
Epoch: 020 | Test Loss: 0.0115501 | Time: 448ms
==> Save the model at epoch 020 with test loss 0.0115501
Epoch: 021 | Loss: 0.0107276 | L2 loss: 0.0107261 | Lip loss: 0.0000015 | Grad norm: 0.409398 | Time: 8s302ms
Epoch: 021 | Test Loss: 0.0115493 | Time: 439ms
==> Save the model at epoch 021 with test loss 0.0115493
Epoch: 022 | Loss: 0.0107226 | L2 loss: 0.0107212 | Lip loss: 0.0000014 | Grad norm: 0.420835 | Time: 8s488ms
Epoch: 022 | Test Loss: 0.0115496 | Time: 448ms
Epoch: 023 | Loss: 0.0107229 | L2 loss: 0.0107214 | Lip loss: 0.0000015 | Grad norm: 0.407952 | Time: 8s646ms
Epoch: 023 | Test Loss: 0.0115488 | Time: 439ms
==> Save the model at epoch 023 with test loss 0.0115488
Epoch: 024 | Loss: 0.0107392 | L2 loss: 0.0107377 | Lip loss: 0.0000015 | Grad norm: 0.440335 | Time: 8s489ms
Epoch: 024 | Test Loss: 0.0115481 | Time: 506ms
==> Save the model at epoch 024 with test loss 0.0115481
Epoch: 025 | Loss: 0.0107249 | L2 loss: 0.0107234 | Lip loss: 0.0000015 | Grad norm: 0.425609 | Time: 8s210ms
Epoch: 025 | Test Loss: 0.0115471 | Time: 441ms
==> Save the model at epoch 025 with test loss 0.0115471
Epoch: 026 | Loss: 0.0107741 | L2 loss: 0.0107727 | Lip loss: 0.0000015 | Grad norm: 0.429689 | Time: 8s84ms
Epoch: 026 | Test Loss: 0.0115470 | Time: 436ms
==> Save the model at epoch 026 with test loss 0.0115470
Epoch: 027 | Loss: 0.0107254 | L2 loss: 0.0107240 | Lip loss: 0.0000014 | Grad norm: 0.419042 | Time: 8s165ms
Epoch: 027 | Test Loss: 0.0115470 | Time: 517ms
Epoch: 028 | Loss: 0.0107282 | L2 loss: 0.0107268 | Lip loss: 0.0000015 | Grad norm: 0.416726 | Time: 8s478ms
Epoch: 028 | Test Loss: 0.0115469 | Time: 463ms
==> Save the model at epoch 028 with test loss 0.0115469
Epoch: 029 | Loss: 0.0107403 | L2 loss: 0.0107389 | Lip loss: 0.0000015 | Grad norm: 0.441739 | Time: 8s662ms
Epoch: 029 | Test Loss: 0.0115469 | Time: 451ms
Epoch: 030 | Loss: 0.0107233 | L2 loss: 0.0107218 | Lip loss: 0.0000015 | Grad norm: 0.447152 | Time: 8s610ms
Epoch: 030 | Test Loss: 0.0115469 | Time: 455ms
==> Save the model at epoch 030 with test loss 0.0115469
Epoch: 031 | Loss: 0.0107513 | L2 loss: 0.0107499 | Lip loss: 0.0000014 | Grad norm: 0.420446 | Time: 8s466ms
Epoch: 031 | Test Loss: 0.0115469 | Time: 450ms
==> Save the model at epoch 031 with test loss 0.0115469
Epoch: 032 | Loss: 0.0107259 | L2 loss: 0.0107243 | Lip loss: 0.0000015 | Grad norm: 0.428643 | Time: 8s233ms
Epoch: 032 | Test Loss: 0.0115469 | Time: 438ms
==> Save the model at epoch 032 with test loss 0.0115469
Epoch: 033 | Loss: 0.0107191 | L2 loss: 0.0107176 | Lip loss: 0.0000015 | Grad norm: 0.436203 | Time: 8s625ms
Epoch: 033 | Test Loss: 0.0115469 | Time: 441ms
Epoch: 034 | Loss: 0.0107205 | L2 loss: 0.0107189 | Lip loss: 0.0000015 | Grad norm: 0.443641 | Time: 8s540ms
Epoch: 034 | Test Loss: 0.0115469 | Time: 450ms
==> Save the model at epoch 034 with test loss 0.0115469
Epoch: 035 | Loss: 0.0107221 | L2 loss: 0.0107207 | Lip loss: 0.0000015 | Grad norm: 0.425937 | Time: 8s550ms
Epoch: 035 | Test Loss: 0.0115469 | Time: 538ms
==> Save the model at epoch 035 with test loss 0.0115469
Epoch: 036 | Loss: 0.0107230 | L2 loss: 0.0107215 | Lip loss: 0.0000014 | Grad norm: 0.438003 | Time: 8s331ms
Epoch: 036 | Test Loss: 0.0115469 | Time: 445ms
Epoch: 037 | Loss: 0.0107195 | L2 loss: 0.0107181 | Lip loss: 0.0000014 | Grad norm: 0.442333 | Time: 8s508ms
Epoch: 037 | Test Loss: 0.0115469 | Time: 442ms
==> Save the model at epoch 037 with test loss 0.0115469
Epoch: 038 | Loss: 0.0107242 | L2 loss: 0.0107227 | Lip loss: 0.0000015 | Grad norm: 0.452371 | Time: 8s401ms
Epoch: 038 | Test Loss: 0.0115469 | Time: 524ms
Epoch: 039 | Loss: 0.0107254 | L2 loss: 0.0107238 | Lip loss: 0.0000015 | Grad norm: 0.427730 | Time: 8s413ms
Epoch: 039 | Test Loss: 0.0115469 | Time: 458ms
Epoch: 040 | Loss: 0.0107182 | L2 loss: 0.0107167 | Lip loss: 0.0000015 | Grad norm: 0.427558 | Time: 9s298ms
Epoch: 040 | Test Loss: 0.0115469 | Time: 478ms
==> Save the model at epoch 040 with test loss 0.0115469
Total time: 6m446ms
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[1. 1.]
==> Output transform to be applied to the neural network (trained):
[1. 1.]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Drawing l2 loss...
==> Drawing lip loss...
==> Process finished.
