==> torch device:  cuda:3
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.50
==> Further split seed:  None
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[1. 1.]
==> Ouput transform to be applied to the neural network:
[1. 1.]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─Linear: 2-1                       [1, 64]                   192
│    └─LeakyReLU: 2-2                    [1, 64]                   --
│    └─Linear: 2-3                       [1, 64]                   4,160
│    └─LeakyReLU: 2-4                    [1, 64]                   --
│    └─Linear: 2-5                       [1, 64]                   4,160
│    └─LeakyReLU: 2-6                    [1, 64]                   --
│    └─Linear: 2-7                       [1, 64]                   4,160
│    └─LeakyReLU: 2-8                    [1, 64]                   --
│    └─Linear: 2-9                       [1, 64]                   4,160
│    └─LeakyReLU: 2-10                   [1, 64]                   --
│    └─Linear: 2-11                      [1, 64]                   4,160
│    └─LeakyReLU: 2-12                   [1, 64]                   --
│    └─Linear: 2-13                      [1, 64]                   4,160
│    └─LeakyReLU: 2-14                   [1, 64]                   --
│    └─Linear: 2-15                      [1, 2]                    130
==========================================================================================
Total params: 25,288
Trainable params: 25,282
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.03
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.10
Estimated Total Size (MB): 0.10
==========================================================================================
==> Saving initial model weights...
==> Start training...
Epoch: 001 | Loss: 0.5676315 | L2 loss: 0.5676315 | Lip loss: 0.0000000 | Grad norm: 2.249562 | Time: 27s999ms
Epoch: 001 | Test Loss: 0.0168672 | Time: 744ms
==> Save the model at epoch 001 with test loss 0.0168672
Epoch: 002 | Loss: 0.0067962 | L2 loss: 0.0067962 | Lip loss: 0.0000000 | Grad norm: 1.129852 | Time: 27s784ms
Epoch: 002 | Test Loss: 0.0034369 | Time: 806ms
==> Save the model at epoch 002 with test loss 0.0034369
Epoch: 003 | Loss: 0.0041067 | L2 loss: 0.0041066 | Lip loss: 0.0000000 | Grad norm: 0.609089 | Time: 27s857ms
Epoch: 003 | Test Loss: 0.0058757 | Time: 819ms
Epoch: 004 | Loss: 0.0042813 | L2 loss: 0.0042813 | Lip loss: 0.0000000 | Grad norm: 0.662695 | Time: 27s737ms
Epoch: 004 | Test Loss: 0.0041400 | Time: 813ms
Epoch: 005 | Loss: 0.0051093 | L2 loss: 0.0051093 | Lip loss: 0.0000000 | Grad norm: 0.713936 | Time: 28s279ms
Epoch: 005 | Test Loss: 0.0069918 | Time: 753ms
Epoch: 006 | Loss: 0.0029256 | L2 loss: 0.0029256 | Lip loss: 0.0000000 | Grad norm: 0.181664 | Time: 28s413ms
Epoch: 006 | Test Loss: 0.0028649 | Time: 741ms
==> Save the model at epoch 006 with test loss 0.0028649
Epoch: 007 | Loss: 0.0028247 | L2 loss: 0.0028247 | Lip loss: 0.0000000 | Grad norm: 0.133926 | Time: 28s756ms
Epoch: 007 | Test Loss: 0.0028564 | Time: 800ms
==> Save the model at epoch 007 with test loss 0.0028564
Epoch: 008 | Loss: 0.0028247 | L2 loss: 0.0028247 | Lip loss: 0.0000000 | Grad norm: 0.147625 | Time: 28s217ms
Epoch: 008 | Test Loss: 0.0028552 | Time: 810ms
==> Save the model at epoch 008 with test loss 0.0028552
Epoch: 009 | Loss: 0.0028387 | L2 loss: 0.0028387 | Lip loss: 0.0000000 | Grad norm: 0.165843 | Time: 28s197ms
Epoch: 009 | Test Loss: 0.0028004 | Time: 810ms
==> Save the model at epoch 009 with test loss 0.0028004
Epoch: 010 | Loss: 0.0028337 | L2 loss: 0.0028337 | Lip loss: 0.0000000 | Grad norm: 0.165974 | Time: 28s449ms
Epoch: 010 | Test Loss: 0.0028375 | Time: 809ms
Epoch: 011 | Loss: 0.0027622 | L2 loss: 0.0027622 | Lip loss: 0.0000000 | Grad norm: 0.099736 | Time: 28s116ms
Epoch: 011 | Test Loss: 0.0027890 | Time: 812ms
==> Save the model at epoch 011 with test loss 0.0027890
Epoch: 012 | Loss: 0.0027614 | L2 loss: 0.0027613 | Lip loss: 0.0000000 | Grad norm: 0.097642 | Time: 28s527ms
Epoch: 012 | Test Loss: 0.0027881 | Time: 743ms
==> Save the model at epoch 012 with test loss 0.0027881
Epoch: 013 | Loss: 0.0027607 | L2 loss: 0.0027607 | Lip loss: 0.0000000 | Grad norm: 0.100680 | Time: 28s275ms
Epoch: 013 | Test Loss: 0.0027866 | Time: 811ms
==> Save the model at epoch 013 with test loss 0.0027866
Epoch: 014 | Loss: 0.0027620 | L2 loss: 0.0027620 | Lip loss: 0.0000000 | Grad norm: 0.105316 | Time: 28s486ms
Epoch: 014 | Test Loss: 0.0027879 | Time: 826ms
Epoch: 015 | Loss: 0.0027617 | L2 loss: 0.0027617 | Lip loss: 0.0000000 | Grad norm: 0.103367 | Time: 28s208ms
Epoch: 015 | Test Loss: 0.0027816 | Time: 730ms
==> Save the model at epoch 015 with test loss 0.0027816
Epoch: 016 | Loss: 0.0027508 | L2 loss: 0.0027508 | Lip loss: 0.0000000 | Grad norm: 0.092044 | Time: 28s354ms
Epoch: 016 | Test Loss: 0.0027775 | Time: 816ms
==> Save the model at epoch 016 with test loss 0.0027775
Epoch: 017 | Loss: 0.0027504 | L2 loss: 0.0027504 | Lip loss: 0.0000000 | Grad norm: 0.090545 | Time: 28s992ms
Epoch: 017 | Test Loss: 0.0027785 | Time: 815ms
Epoch: 018 | Loss: 0.0027505 | L2 loss: 0.0027505 | Lip loss: 0.0000000 | Grad norm: 0.088851 | Time: 28s444ms
Epoch: 018 | Test Loss: 0.0027770 | Time: 801ms
==> Save the model at epoch 018 with test loss 0.0027770
Epoch: 019 | Loss: 0.0027509 | L2 loss: 0.0027509 | Lip loss: 0.0000000 | Grad norm: 0.093830 | Time: 27s345ms
Epoch: 019 | Test Loss: 0.0027771 | Time: 802ms
Epoch: 020 | Loss: 0.0027500 | L2 loss: 0.0027500 | Lip loss: 0.0000000 | Grad norm: 0.091807 | Time: 27s637ms
Epoch: 020 | Test Loss: 0.0027841 | Time: 806ms
Epoch: 021 | Loss: 0.0027498 | L2 loss: 0.0027498 | Lip loss: 0.0000000 | Grad norm: 0.090577 | Time: 27s750ms
Epoch: 021 | Test Loss: 0.0027764 | Time: 752ms
==> Save the model at epoch 021 with test loss 0.0027764
Epoch: 022 | Loss: 0.0027486 | L2 loss: 0.0027486 | Lip loss: 0.0000000 | Grad norm: 0.087281 | Time: 27s987ms
Epoch: 022 | Test Loss: 0.0027763 | Time: 812ms
==> Save the model at epoch 022 with test loss 0.0027763
Epoch: 023 | Loss: 0.0027486 | L2 loss: 0.0027486 | Lip loss: 0.0000000 | Grad norm: 0.090539 | Time: 27s810ms
Epoch: 023 | Test Loss: 0.0027764 | Time: 806ms
Epoch: 024 | Loss: 0.0027487 | L2 loss: 0.0027487 | Lip loss: 0.0000000 | Grad norm: 0.089124 | Time: 28s673ms
Epoch: 024 | Test Loss: 0.0027765 | Time: 748ms
Epoch: 025 | Loss: 0.0027483 | L2 loss: 0.0027483 | Lip loss: 0.0000000 | Grad norm: 0.087881 | Time: 28s885ms
Epoch: 025 | Test Loss: 0.0027763 | Time: 728ms
==> Save the model at epoch 025 with test loss 0.0027763
Epoch: 026 | Loss: 0.0027481 | L2 loss: 0.0027481 | Lip loss: 0.0000000 | Grad norm: 0.088102 | Time: 28s102ms
Epoch: 026 | Test Loss: 0.0027763 | Time: 785ms
==> Save the model at epoch 026 with test loss 0.0027763
Epoch: 027 | Loss: 0.0027481 | L2 loss: 0.0027481 | Lip loss: 0.0000000 | Grad norm: 0.088845 | Time: 28s180ms
Epoch: 027 | Test Loss: 0.0027763 | Time: 752ms
Epoch: 028 | Loss: 0.0027481 | L2 loss: 0.0027481 | Lip loss: 0.0000000 | Grad norm: 0.089066 | Time: 28s357ms
Epoch: 028 | Test Loss: 0.0027763 | Time: 809ms
Epoch: 029 | Loss: 0.0027480 | L2 loss: 0.0027480 | Lip loss: 0.0000000 | Grad norm: 0.088956 | Time: 28s220ms
Epoch: 029 | Test Loss: 0.0027763 | Time: 815ms
Epoch: 030 | Loss: 0.0027478 | L2 loss: 0.0027478 | Lip loss: 0.0000000 | Grad norm: 0.089038 | Time: 28s817ms
Epoch: 030 | Test Loss: 0.0027763 | Time: 827ms
Epoch: 031 | Loss: 0.0027485 | L2 loss: 0.0027485 | Lip loss: 0.0000000 | Grad norm: 0.089591 | Time: 28s731ms
Epoch: 031 | Test Loss: 0.0027763 | Time: 813ms
Epoch: 032 | Loss: 0.0027484 | L2 loss: 0.0027484 | Lip loss: 0.0000000 | Grad norm: 0.087565 | Time: 28s473ms
Epoch: 032 | Test Loss: 0.0027763 | Time: 799ms
Epoch: 033 | Loss: 0.0027483 | L2 loss: 0.0027483 | Lip loss: 0.0000000 | Grad norm: 0.089476 | Time: 28s492ms
Epoch: 033 | Test Loss: 0.0027763 | Time: 743ms
Epoch: 034 | Loss: 0.0027485 | L2 loss: 0.0027484 | Lip loss: 0.0000000 | Grad norm: 0.089505 | Time: 28s333ms
Epoch: 034 | Test Loss: 0.0027763 | Time: 815ms
Epoch: 035 | Loss: 0.0027485 | L2 loss: 0.0027485 | Lip loss: 0.0000000 | Grad norm: 0.087816 | Time: 28s478ms
Epoch: 035 | Test Loss: 0.0027763 | Time: 809ms
Epoch: 036 | Loss: 0.0027486 | L2 loss: 0.0027486 | Lip loss: 0.0000000 | Grad norm: 0.092726 | Time: 27s951ms
Epoch: 036 | Test Loss: 0.0027763 | Time: 749ms
Epoch: 037 | Loss: 0.0027486 | L2 loss: 0.0027486 | Lip loss: 0.0000000 | Grad norm: 0.088788 | Time: 27s329ms
Epoch: 037 | Test Loss: 0.0027763 | Time: 803ms
Epoch: 038 | Loss: 0.0027486 | L2 loss: 0.0027486 | Lip loss: 0.0000000 | Grad norm: 0.090233 | Time: 28s629ms
Epoch: 038 | Test Loss: 0.0027763 | Time: 826ms
Epoch: 039 | Loss: 0.0027475 | L2 loss: 0.0027475 | Lip loss: 0.0000000 | Grad norm: 0.088782 | Time: 28s600ms
Epoch: 039 | Test Loss: 0.0027763 | Time: 809ms
Epoch: 040 | Loss: 0.0027483 | L2 loss: 0.0027483 | Lip loss: 0.0000000 | Grad norm: 0.087057 | Time: 29s16ms
Epoch: 040 | Test Loss: 0.0027763 | Time: 807ms
Total time: 19m22s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[1. 1.]
==> Output transform to be applied to the neural network (trained):
[1. 1.]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Drawing l2 loss...
==> Drawing lip loss...
==> Process finished.
