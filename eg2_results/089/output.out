==> torch device:  cuda:0
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 1.00
==> Further split seed:  None
==> Lipschitz constant: 64.00
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[0.496845   0.52004784]
==> Ouput transform to be applied to the neural network:
[1.9242 2.0182]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─SandwichFc: 2-1                   [1, 64]                   4,353
│    └─SandwichFc: 2-2                   [1, 64]                   8,321
│    └─SandwichFc: 2-3                   [1, 64]                   8,321
│    └─SandwichFc: 2-4                   [1, 64]                   8,321
│    └─SandwichFc: 2-5                   [1, 64]                   8,321
│    └─SandwichFc: 2-6                   [1, 64]                   8,321
│    └─SandwichFc: 2-7                   [1, 64]                   8,321
│    └─SandwichLin: 2-8                  [1, 2]                    135
├─Sequential: 1-2                        [1, 2]                    (recursive)
│    └─SandwichFc: 2-9                   [1, 64]                   (recursive)
│    └─SandwichFc: 2-10                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-11                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-12                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-13                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-14                  [1, 64]                   (recursive)
│    └─SandwichFc: 2-15                  [1, 64]                   (recursive)
│    └─SandwichLin: 2-16                 [1, 2]                    (recursive)
==========================================================================================
Total params: 54,420
Trainable params: 54,414
Non-trainable params: 6
Total mult-adds (Units.MEGABYTES): 0.11
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.22
Estimated Total Size (MB): 0.22
==========================================================================================
==> Saving initial model weights...
==> Start training...
==> Number of param_groups in optimizer: 1
Epoch: 001 | Train Loss: 7.3441756 | Grad norm: 143.757921 | Time: 17s482ms
Epoch: 001 | Test Loss: 7.4192689 | Time: 573ms
==> Save the model at epoch 001 with test loss 7.4192689
Epoch: 002 | Train Loss: 0.1341571 | Grad norm: 12.651374 | Time: 17s107ms
Epoch: 002 | Test Loss: 0.0175633 | Time: 563ms
==> Save the model at epoch 002 with test loss 0.0175633
Epoch: 003 | Train Loss: 0.0239222 | Grad norm: 7.525874 | Time: 17s461ms
Epoch: 003 | Test Loss: 0.0165028 | Time: 603ms
==> Save the model at epoch 003 with test loss 0.0165028
Epoch: 004 | Train Loss: 0.0273987 | Grad norm: 6.301679 | Time: 17s789ms
Epoch: 004 | Test Loss: 0.0241421 | Time: 589ms
Epoch: 005 | Train Loss: 0.0314841 | Grad norm: 6.200851 | Time: 17s972ms
Epoch: 005 | Test Loss: 0.0210075 | Time: 666ms
Epoch: 006 | Train Loss: 0.0321936 | Grad norm: 5.972979 | Time: 17s90ms
Epoch: 006 | Test Loss: 0.0195087 | Time: 684ms
Epoch: 007 | Train Loss: 0.0318070 | Grad norm: 5.811891 | Time: 17s111ms
Epoch: 007 | Test Loss: 0.0206797 | Time: 577ms
Epoch: 008 | Train Loss: 0.0340468 | Grad norm: 5.627152 | Time: 17s281ms
Epoch: 008 | Test Loss: 0.0297040 | Time: 579ms
Epoch: 009 | Train Loss: 0.0361795 | Grad norm: 5.489387 | Time: 17s525ms
Epoch: 009 | Test Loss: 0.0280883 | Time: 682ms
Epoch: 010 | Train Loss: 0.0304166 | Grad norm: 4.958532 | Time: 18s729ms
Epoch: 010 | Test Loss: 0.0307938 | Time: 636ms
Epoch: 011 | Train Loss: 0.0275813 | Grad norm: 4.381241 | Time: 17s654ms
Epoch: 011 | Test Loss: 0.0205807 | Time: 589ms
Epoch: 012 | Train Loss: 0.0245894 | Grad norm: 3.959349 | Time: 17s484ms
Epoch: 012 | Test Loss: 0.0184851 | Time: 616ms
Epoch: 013 | Train Loss: 0.0211388 | Grad norm: 3.466163 | Time: 17s794ms
Epoch: 013 | Test Loss: 0.0213779 | Time: 566ms
Epoch: 014 | Train Loss: 0.0193441 | Grad norm: 3.252560 | Time: 17s232ms
Epoch: 014 | Test Loss: 0.0161180 | Time: 575ms
==> Save the model at epoch 014 with test loss 0.0161180
Epoch: 015 | Train Loss: 0.0167807 | Grad norm: 2.890036 | Time: 17s168ms
Epoch: 015 | Test Loss: 0.0186641 | Time: 599ms
Epoch: 016 | Train Loss: 0.0167447 | Grad norm: 2.750493 | Time: 17s318ms
Epoch: 016 | Test Loss: 0.0095088 | Time: 603ms
==> Save the model at epoch 016 with test loss 0.0095088
Epoch: 017 | Train Loss: 0.0160604 | Grad norm: 2.547494 | Time: 17s297ms
Epoch: 017 | Test Loss: 0.0178222 | Time: 624ms
Epoch: 018 | Train Loss: 0.0140046 | Grad norm: 2.325706 | Time: 17s438ms
Epoch: 018 | Test Loss: 0.0277612 | Time: 604ms
Epoch: 019 | Train Loss: 0.0152604 | Grad norm: 2.337445 | Time: 17s397ms
Epoch: 019 | Test Loss: 0.0177394 | Time: 643ms
Epoch: 020 | Train Loss: 0.0142589 | Grad norm: 2.245693 | Time: 17s784ms
Epoch: 020 | Test Loss: 0.0114047 | Time: 651ms
Epoch: 021 | Train Loss: 0.0118344 | Grad norm: 1.742111 | Time: 18s262ms
Epoch: 021 | Test Loss: 0.0129077 | Time: 614ms
Epoch: 022 | Train Loss: 0.0123721 | Grad norm: 1.938510 | Time: 18s3ms
Epoch: 022 | Test Loss: 0.0159219 | Time: 596ms
Epoch: 023 | Train Loss: 0.0106069 | Grad norm: 1.596144 | Time: 17s682ms
Epoch: 023 | Test Loss: 0.0091301 | Time: 575ms
==> Save the model at epoch 023 with test loss 0.0091301
Epoch: 024 | Train Loss: 0.0101141 | Grad norm: 1.499665 | Time: 17s828ms
Epoch: 024 | Test Loss: 0.0108948 | Time: 633ms
Epoch: 025 | Train Loss: 0.0092052 | Grad norm: 1.281609 | Time: 17s482ms
Epoch: 025 | Test Loss: 0.0082988 | Time: 595ms
==> Save the model at epoch 025 with test loss 0.0082988
Epoch: 026 | Train Loss: 0.0089658 | Grad norm: 1.238243 | Time: 17s608ms
Epoch: 026 | Test Loss: 0.0093082 | Time: 624ms
Epoch: 027 | Train Loss: 0.0085557 | Grad norm: 1.067055 | Time: 17s622ms
Epoch: 027 | Test Loss: 0.0089514 | Time: 574ms
Epoch: 028 | Train Loss: 0.0082562 | Grad norm: 0.994617 | Time: 17s297ms
Epoch: 028 | Test Loss: 0.0085161 | Time: 583ms
Epoch: 029 | Train Loss: 0.0080797 | Grad norm: 0.983423 | Time: 17s424ms
Epoch: 029 | Test Loss: 0.0108892 | Time: 586ms
Epoch: 030 | Train Loss: 0.0078822 | Grad norm: 0.911012 | Time: 17s357ms
Epoch: 030 | Test Loss: 0.0084718 | Time: 594ms
Epoch: 031 | Train Loss: 0.0075814 | Grad norm: 0.835808 | Time: 17s484ms
Epoch: 031 | Test Loss: 0.0074986 | Time: 642ms
==> Save the model at epoch 031 with test loss 0.0074986
Epoch: 032 | Train Loss: 0.0073009 | Grad norm: 0.681233 | Time: 17s366ms
Epoch: 032 | Test Loss: 0.0071967 | Time: 650ms
==> Save the model at epoch 032 with test loss 0.0071967
Epoch: 033 | Train Loss: 0.0070474 | Grad norm: 0.599473 | Time: 18s17ms
Epoch: 033 | Test Loss: 0.0071232 | Time: 640ms
==> Save the model at epoch 033 with test loss 0.0071232
Epoch: 034 | Train Loss: 0.0069904 | Grad norm: 0.609849 | Time: 18s9ms
Epoch: 034 | Test Loss: 0.0070137 | Time: 679ms
==> Save the model at epoch 034 with test loss 0.0070137
Epoch: 035 | Train Loss: 0.0068089 | Grad norm: 0.531949 | Time: 17s696ms
Epoch: 035 | Test Loss: 0.0066393 | Time: 631ms
==> Save the model at epoch 035 with test loss 0.0066393
Epoch: 036 | Train Loss: 0.0066812 | Grad norm: 0.469707 | Time: 18s48ms
Epoch: 036 | Test Loss: 0.0067216 | Time: 664ms
Epoch: 037 | Train Loss: 0.0065989 | Grad norm: 0.421564 | Time: 17s315ms
Epoch: 037 | Test Loss: 0.0066020 | Time: 594ms
==> Save the model at epoch 037 with test loss 0.0066020
Epoch: 038 | Train Loss: 0.0065117 | Grad norm: 0.375205 | Time: 17s178ms
Epoch: 038 | Test Loss: 0.0067042 | Time: 653ms
Epoch: 039 | Train Loss: 0.0064682 | Grad norm: 0.333973 | Time: 17s256ms
Epoch: 039 | Test Loss: 0.0064861 | Time: 592ms
==> Save the model at epoch 039 with test loss 0.0064861
Epoch: 040 | Train Loss: 0.0064194 | Grad norm: 0.302865 | Time: 17s145ms
Epoch: 040 | Test Loss: 0.0064601 | Time: 573ms
==> Save the model at epoch 040 with test loss 0.0064601
Total time: 12m6s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[0.496845   0.52004784]
==> Output transform to be applied to the neural network (trained):
[1.9242 2.0182]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Process finished.
