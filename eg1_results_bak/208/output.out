==> torch device:  cuda:3
==> Test-Train split: test_ratio = 0.20
==> Test-Train split seed:  None
==> Further split: further_train_ratio = 0.25
==> Further split seed:  None
==> Input bias to be applied to the neural network:
[0. 0.]
==> Input transform to be applied to the neural network:
[1. 1.]
==> Ouput transform to be applied to the neural network:
[1. 1.]
==> Evaluating model...
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NeuralNetwork                            [1, 2]                    6
├─Sequential: 1-1                        [1, 2]                    --
│    └─Linear: 2-1                       [1, 64]                   192
│    └─LeakyReLU: 2-2                    [1, 64]                   --
│    └─Linear: 2-3                       [1, 64]                   4,160
│    └─LeakyReLU: 2-4                    [1, 64]                   --
│    └─Linear: 2-5                       [1, 64]                   4,160
│    └─LeakyReLU: 2-6                    [1, 64]                   --
│    └─Linear: 2-7                       [1, 64]                   4,160
│    └─LeakyReLU: 2-8                    [1, 64]                   --
│    └─Linear: 2-9                       [1, 64]                   4,160
│    └─LeakyReLU: 2-10                   [1, 64]                   --
│    └─Linear: 2-11                      [1, 64]                   4,160
│    └─LeakyReLU: 2-12                   [1, 64]                   --
│    └─Linear: 2-13                      [1, 64]                   4,160
│    └─LeakyReLU: 2-14                   [1, 64]                   --
│    └─Linear: 2-15                      [1, 2]                    130
==========================================================================================
Total params: 25,288
Trainable params: 25,282
Non-trainable params: 6
Total mult-adds (M): 0.03
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.10
Estimated Total Size (MB): 0.10
==========================================================================================
==> Saving initial model weights...
==> Start training...
Epoch: 001 | Loss: 10.7733226 | L2 loss: 10.7716349 | Lip loss: 0.0016877 | Grad norm: 21.692028 | Time: 12s802ms
Epoch: 001 | Test Loss: 0.0598655 | Time: 551ms
==> Save the model at epoch 001 with test loss 0.0598655
Epoch: 002 | Loss: 0.1588923 | L2 loss: 0.1567274 | Lip loss: 0.0021649 | Grad norm: 22.460492 | Time: 12s792ms
Epoch: 002 | Test Loss: 0.0250601 | Time: 586ms
==> Save the model at epoch 002 with test loss 0.0250601
Epoch: 003 | Loss: 0.0502994 | L2 loss: 0.0482090 | Lip loss: 0.0020904 | Grad norm: 10.877695 | Time: 12s296ms
Epoch: 003 | Test Loss: 0.0264531 | Time: 539ms
Epoch: 004 | Loss: 0.0323921 | L2 loss: 0.0303139 | Lip loss: 0.0020782 | Grad norm: 8.213606 | Time: 11s844ms
Epoch: 004 | Test Loss: 0.0278315 | Time: 538ms
Epoch: 005 | Loss: 0.0676680 | L2 loss: 0.0655817 | Lip loss: 0.0020863 | Grad norm: 8.916660 | Time: 11s848ms
Epoch: 005 | Test Loss: 0.0635817 | Time: 601ms
Epoch: 006 | Loss: 0.0138541 | L2 loss: 0.0117944 | Lip loss: 0.0020596 | Grad norm: 1.581011 | Time: 11s839ms
Epoch: 006 | Test Loss: 0.0087899 | Time: 538ms
==> Save the model at epoch 006 with test loss 0.0087899
Epoch: 007 | Loss: 0.0106294 | L2 loss: 0.0085779 | Lip loss: 0.0020514 | Grad norm: 0.910425 | Time: 11s842ms
Epoch: 007 | Test Loss: 0.0084169 | Time: 543ms
==> Save the model at epoch 007 with test loss 0.0084169
Epoch: 008 | Loss: 0.0103353 | L2 loss: 0.0082840 | Lip loss: 0.0020512 | Grad norm: 0.749759 | Time: 11s900ms
Epoch: 008 | Test Loss: 0.0081474 | Time: 541ms
==> Save the model at epoch 008 with test loss 0.0081474
Epoch: 009 | Loss: 0.0103989 | L2 loss: 0.0083521 | Lip loss: 0.0020467 | Grad norm: 0.904810 | Time: 12s938ms
Epoch: 009 | Test Loss: 0.0080935 | Time: 551ms
==> Save the model at epoch 009 with test loss 0.0080935
Epoch: 010 | Loss: 0.0103594 | L2 loss: 0.0083156 | Lip loss: 0.0020438 | Grad norm: 0.985754 | Time: 12s576ms
Epoch: 010 | Test Loss: 0.0079480 | Time: 539ms
==> Save the model at epoch 010 with test loss 0.0079480
Epoch: 011 | Loss: 0.0099022 | L2 loss: 0.0078547 | Lip loss: 0.0020475 | Grad norm: 0.478975 | Time: 11s911ms
Epoch: 011 | Test Loss: 0.0076029 | Time: 539ms
==> Save the model at epoch 011 with test loss 0.0076029
Epoch: 012 | Loss: 0.0098494 | L2 loss: 0.0078068 | Lip loss: 0.0020426 | Grad norm: 0.400868 | Time: 11s831ms
Epoch: 012 | Test Loss: 0.0076433 | Time: 539ms
Epoch: 013 | Loss: 0.0098685 | L2 loss: 0.0078230 | Lip loss: 0.0020454 | Grad norm: 0.433431 | Time: 11s841ms
Epoch: 013 | Test Loss: 0.0076100 | Time: 601ms
Epoch: 014 | Loss: 0.0098453 | L2 loss: 0.0078039 | Lip loss: 0.0020414 | Grad norm: 0.417855 | Time: 11s847ms
Epoch: 014 | Test Loss: 0.0075861 | Time: 541ms
==> Save the model at epoch 014 with test loss 0.0075861
Epoch: 015 | Loss: 0.0098315 | L2 loss: 0.0077891 | Lip loss: 0.0020424 | Grad norm: 0.393245 | Time: 11s844ms
Epoch: 015 | Test Loss: 0.0075805 | Time: 538ms
==> Save the model at epoch 015 with test loss 0.0075805
Epoch: 016 | Loss: 0.0097946 | L2 loss: 0.0077505 | Lip loss: 0.0020441 | Grad norm: 0.356337 | Time: 11s840ms
Epoch: 016 | Test Loss: 0.0075697 | Time: 597ms
==> Save the model at epoch 016 with test loss 0.0075697
Epoch: 017 | Loss: 0.0098024 | L2 loss: 0.0077532 | Lip loss: 0.0020492 | Grad norm: 0.344060 | Time: 11s844ms
Epoch: 017 | Test Loss: 0.0075704 | Time: 539ms
Epoch: 018 | Loss: 0.0097923 | L2 loss: 0.0077494 | Lip loss: 0.0020429 | Grad norm: 0.339042 | Time: 11s848ms
Epoch: 018 | Test Loss: 0.0075723 | Time: 539ms
Epoch: 019 | Loss: 0.0098087 | L2 loss: 0.0077571 | Lip loss: 0.0020517 | Grad norm: 0.366934 | Time: 11s900ms
Epoch: 019 | Test Loss: 0.0075695 | Time: 541ms
==> Save the model at epoch 019 with test loss 0.0075695
Epoch: 020 | Loss: 0.0097952 | L2 loss: 0.0077511 | Lip loss: 0.0020441 | Grad norm: 0.365193 | Time: 11s837ms
Epoch: 020 | Test Loss: 0.0075689 | Time: 541ms
==> Save the model at epoch 020 with test loss 0.0075689
Epoch: 021 | Loss: 0.0098034 | L2 loss: 0.0077574 | Lip loss: 0.0020460 | Grad norm: 0.338538 | Time: 11s833ms
Epoch: 021 | Test Loss: 0.0075682 | Time: 540ms
==> Save the model at epoch 021 with test loss 0.0075682
Epoch: 022 | Loss: 0.0097966 | L2 loss: 0.0077486 | Lip loss: 0.0020479 | Grad norm: 0.348573 | Time: 11s887ms
Epoch: 022 | Test Loss: 0.0075676 | Time: 539ms
==> Save the model at epoch 022 with test loss 0.0075676
Epoch: 023 | Loss: 0.0097881 | L2 loss: 0.0077443 | Lip loss: 0.0020438 | Grad norm: 0.340938 | Time: 11s833ms
Epoch: 023 | Test Loss: 0.0075681 | Time: 540ms
Epoch: 024 | Loss: 0.0097931 | L2 loss: 0.0077436 | Lip loss: 0.0020496 | Grad norm: 0.331861 | Time: 11s831ms
Epoch: 024 | Test Loss: 0.0075673 | Time: 539ms
==> Save the model at epoch 024 with test loss 0.0075673
Epoch: 025 | Loss: 0.0097929 | L2 loss: 0.0077479 | Lip loss: 0.0020450 | Grad norm: 0.355651 | Time: 12s970ms
Epoch: 025 | Test Loss: 0.0075674 | Time: 552ms
Epoch: 026 | Loss: 0.0097936 | L2 loss: 0.0077521 | Lip loss: 0.0020415 | Grad norm: 0.331587 | Time: 12s705ms
Epoch: 026 | Test Loss: 0.0075674 | Time: 545ms
Epoch: 027 | Loss: 0.0097894 | L2 loss: 0.0077444 | Lip loss: 0.0020450 | Grad norm: 0.336187 | Time: 13s285ms
Epoch: 027 | Test Loss: 0.0075675 | Time: 544ms
Epoch: 028 | Loss: 0.0097867 | L2 loss: 0.0077450 | Lip loss: 0.0020417 | Grad norm: 0.337076 | Time: 11s820ms
Epoch: 028 | Test Loss: 0.0075675 | Time: 538ms
Epoch: 029 | Loss: 0.0097883 | L2 loss: 0.0077426 | Lip loss: 0.0020456 | Grad norm: 0.345137 | Time: 11s831ms
Epoch: 029 | Test Loss: 0.0075675 | Time: 546ms
Epoch: 030 | Loss: 0.0097824 | L2 loss: 0.0077418 | Lip loss: 0.0020406 | Grad norm: 0.336386 | Time: 11s884ms
Epoch: 030 | Test Loss: 0.0075675 | Time: 540ms
Epoch: 031 | Loss: 0.0097979 | L2 loss: 0.0077565 | Lip loss: 0.0020414 | Grad norm: 0.336949 | Time: 11s829ms
Epoch: 031 | Test Loss: 0.0075675 | Time: 536ms
Epoch: 032 | Loss: 0.0098041 | L2 loss: 0.0077548 | Lip loss: 0.0020492 | Grad norm: 0.349779 | Time: 11s820ms
Epoch: 032 | Test Loss: 0.0075675 | Time: 597ms
Epoch: 033 | Loss: 0.0097878 | L2 loss: 0.0077425 | Lip loss: 0.0020453 | Grad norm: 0.338117 | Time: 11s816ms
Epoch: 033 | Test Loss: 0.0075675 | Time: 541ms
Epoch: 034 | Loss: 0.0097893 | L2 loss: 0.0077427 | Lip loss: 0.0020467 | Grad norm: 0.329896 | Time: 11s821ms
Epoch: 034 | Test Loss: 0.0075675 | Time: 541ms
Epoch: 035 | Loss: 0.0097834 | L2 loss: 0.0077450 | Lip loss: 0.0020385 | Grad norm: 0.338486 | Time: 12s559ms
Epoch: 035 | Test Loss: 0.0075675 | Time: 571ms
Epoch: 036 | Loss: 0.0097855 | L2 loss: 0.0077470 | Lip loss: 0.0020384 | Grad norm: 0.349767 | Time: 12s152ms
Epoch: 036 | Test Loss: 0.0075675 | Time: 542ms
Epoch: 037 | Loss: 0.0097864 | L2 loss: 0.0077431 | Lip loss: 0.0020433 | Grad norm: 0.329666 | Time: 11s838ms
Epoch: 037 | Test Loss: 0.0075675 | Time: 541ms
Epoch: 038 | Loss: 0.0097862 | L2 loss: 0.0077415 | Lip loss: 0.0020447 | Grad norm: 0.349026 | Time: 11s975ms
Epoch: 038 | Test Loss: 0.0075675 | Time: 555ms
Epoch: 039 | Loss: 0.0097833 | L2 loss: 0.0077423 | Lip loss: 0.0020410 | Grad norm: 0.337455 | Time: 13s375ms
Epoch: 039 | Test Loss: 0.0075675 | Time: 547ms
Epoch: 040 | Loss: 0.0097993 | L2 loss: 0.0077513 | Lip loss: 0.0020480 | Grad norm: 0.375528 | Time: 12s785ms
Epoch: 040 | Test Loss: 0.0075675 | Time: 544ms
Total time: 8m27s
==> Saving trained model weights...
==> Input bias to be applied to the neural network (trained):
[0. 0.]
==> Input transform to be applied to the neural network (trained):
[1. 1.]
==> Output transform to be applied to the neural network (trained):
[1. 1.]
==> Saving training info...
==> Drawing training loss...
==> Drawing grad norm...
==> Drawing testing loss...
==> Drawing l2 loss...
==> Drawing lip loss...
==> Process finished.
